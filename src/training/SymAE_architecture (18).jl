### A Pluto.jl notebook ###
# v0.20.21

using Markdown
using InteractiveUtils

# ‚ïî‚ïê‚ï° d73472ff-9e09-45b0-8811-b7dd8d820358
using CUDA,
    cuDNN,
    Enzyme,
    Flux,
    MLUtils,
    Statistics,
    PlutoUI,
    LinearAlgebra,
    ProgressLogging,
    Optimisers,
    FFTW,
    DSP,
    PlutoPlotly,
    BlackBoxOptim,
    Metaheuristics,
    Random,
    ParameterSchedulers,
    Metalhead

# ‚ïî‚ïê‚ï° 461f0505-2230-4b84-b6c6-1a9730808437
md"""# Symmetric Variational Autoencoders"""

# ‚ïî‚ïê‚ï° 97ae4222-5a3e-4cbd-b4d1-aa028d3e4ca8
TableOfContents(include_definitions=true)

# ‚ïî‚ïê‚ï° 26fb86d5-c844-469a-aef5-ed3c2a9ba949
xpu = gpu

# ‚ïî‚ïê‚ï° a91e28fb-e769-418d-953f-0e0bb366d853
md"""
## Parameters
- nt: number of samples in time
- ntau: number of waveforms used per step (as large as your GPU memory supports)
- p: length of coherent code per each coherent code category
- k: number of coherent information categories
- q: length of nuisance code for each waveform
- beta: custom weight of the KL terms in this order [[nuisance], [coherent, lambda]]
- batchsize: because of stochastic gradient descent
- nsteps: how long you want a single epoch to be?
- network_type:
  - ConvAE() standard choice
  - DenseAE() don't use unless you want to quickly test something
- transformer:
  - :spatial each waveform is time shifted prior to encoding
  - :spatial_state each state is time shifted prior to encoding
  - :null 
- spatial_transformer_gamma::Float32 = 0.5f0
"""

# ‚ïî‚ïê‚ï° 6db97fc1-8f11-42df-bffe-f86b8619a399
Base.@kwdef struct SymAE_Para
    nt::Int
    p::Int
    k::Int = 1
    q::Int
    network_type = ConvAE()
    transformer::Symbol = :null
    seed = nothing
end

# ‚ïî‚ïê‚ï° 29d41554-3a0a-4972-a9e5-54c998429acd
md"## Data Generator"

# ‚ïî‚ïê‚ï° fc228dea-21fc-4fcd-82a9-7ac3bc7ee722
"""
Returns BatchView for each state, after shuffling the data instances and picking `ntau` at a time.
"""
function get_batchviews(dvec, ntau=20)
    X = map(dvec) do d
        BatchView(shuffleobs(ObsView(d)), batchsize=ntau, partial=false)
    end
    return X
end

# ‚ïî‚ïê‚ï° 7c39a024-bf46-4024-b0da-a4d6092e864d
"""
X is generated using get_batchviews, use this method to sample a datapoint of a given batch-size from X.
"""
function get_sample(X, batchsize)
    stack(map(1:batchsize) do i
            randobs(randobs(X))
        end, dims=3)
end

# ‚ïî‚ïê‚ï° 139490d1-5931-4a18-9f74-c391064a3383
"""
Returns data iterator `X` where each datapoint is generated by randomly picking  `ntau` instances from a particular state.
During training, it is very important to mix instances from different states in each batch. In other words, a small batch size, e.g., `1`, is observed not to disentangle coherent from nuisance information. Therefore, it is recommended to set the batch size as high as possible.

* `nsteps` : number of steps per epoch
* `ntau` : number of instances in each datapoint (typically 20)
* `dvec` : a vector where the elements are measured instances from different states
* `batchsize` : number of data points used in each batch for training
"""
function get_data_iterator(dvec; nsteps=1000, batchsize=256, ntau=20)
    drepeat = Flux.stack([randobs(randobs(dvec), ntau) for i = 1:nsteps*batchsize], dims=3)
    return DataLoader(drepeat, shuffle=true, batchsize=batchsize, partial=false, buffer=true, parallel=true)
end

# ‚ïî‚ïê‚ï° 7c59cbf9-38d5-45fb-bf7d-9af8f241ccf6
"""
Same as above but also gives class labels
"""
function get_data_iterator_with_class_labels(dvec; nsteps=1000, batchsize=256, ntau=20)
    D = map(1:nsteps*batchsize) do i
        d = randobs((dvec, 1:length(dvec)))
        d1 = randobs(first(d), ntau)
        dlabel = fill(last(d), 1, ntau)
        (d1, dlabel)
    end
    drepeat = Flux.stack(first.(D), dims=3)
    labelrepeat = Flux.stack(last.(D), dims=3)
    return DataLoader((drepeat, labelrepeat), shuffle=true, batchsize=batchsize, partial=false, buffer=true, parallel=true)
end

# ‚ïî‚ïê‚ï° ce690827-fa3f-48bc-bc09-1df5ee15f683
md"## Architecture"

# ‚ïî‚ïê‚ï° a5302fa2-4f67-4ed6-96ce-dda78a160ffe
# activation = gelu
activation = x -> leakyrelu(x, 0.1)

# ‚ïî‚ïê‚ï° 1121e34c-ca35-4f68-8283-eca514928654
"""
get symae
"""
function get_symae(para)
    Random.seed!(para.seed)

    model =
        if (typeof(para.network_type) == ViTConvAE)
            SymVAETrunk(get_symae(para.network_type, para.nt, para.p, para.q, para.k), para.k)
        else
            SymVAE(get_symae(para.network_type, para.nt, para.p, para.q, para.k), para.k)
        end
    # commented if we want to use full transformer, not just time shift transformer (later)
    # 		sampling_grid =
    #            cat(
    #                reshape(collect(LinRange(-1.0, 1.0, para.nt)), 1, :, 1),
    #                ones(1, para.nt, 1),
    #                dims=1,
    #            ) |> xpu

    # Wrap with spatial transformer if necessary
    # sampling_grid =
    #     cat(
    #         reshape(collect(LinRange(-1.0, 1.0, para.nt)), 1, :, 1),
    #         ones(1, para.nt, 1),
    #         dims = 1,
    #     ) |> xpu
    sampling_grid = xpu(
        im .*
        Float32.(
            fftfreq(para.nt) * 2.0f0 * pi * para.nt * 0.5f0
        ),
    )
    model =
        if (para.transformer == :spatial)
            transformer = get_dense_transformer(para.nt, nt_hidden=para.nt)
            transformerb = BroadcastSpatialTransformer(transformer)
            Spatial_Transformer(model, transformerb, sampling_grid)
        elseif (para.transformer == :spatial_state)
            transformer = get_dense_transformer(para.nt, nt_hidden=para.nt)
            transformerb = BroadcastSpatialStateTransformer(transformer)
            Spatial_Transformer(model, transformerb, sampling_grid)
        else
            model
        end

    loss_history = (
        train_mse=Vector{Float32}(undef, 0),
        test_mse=Vector{Float32}(undef, 0),
        train_neg_llh=Vector{Float32}(undef, 0),
        test_neg_llh=Vector{Float32}(undef, 0),
        train_kl=Vector{Float32}(undef, 0),
        test_kl=Vector{Float32}(undef, 0),
        train_neg_elbo=Vector{Float32}(undef, 0),
        test_neg_elbo=Vector{Float32}(undef, 0),
    )
    return model, loss_history
end

# ‚ïî‚ïê‚ï° ae96f920-5828-4c5f-b69f-48d8c4fee378
md"## Dense Networks"

# ‚ïî‚ïê‚ï° 96aebf7d-2112-4a4d-9993-6f53f40ffca5
function generate_dense_chain(
    nt,
    p,
    nlayers,
    output_activation,
    flat_flag=false,
    ;
    nt_hidden=nt,
)
    if (flat_flag)
        lp = fill(nt_hidden, nlayers + 1)
    else
        lp = floor.(Int, LinRange(nt, p, nlayers + 1))
    end
    layers = []

    # make input 3D
    push!(layers, x -> cat(x, dims=3))

    # Add input layer
    push!(layers, Dense(nt, lp[2], activation))

    # Add hidden layers
    for il = 2:nlayers-1
        push!(layers, Dense(lp[il], lp[il+1], activation))
    end

    # Add output layer
    push!(layers, Dense(lp[nlayers], p, output_activation))

    return layers
end

# ‚ïî‚ïê‚ï° ea372a8f-212f-425d-947c-b57bba6b5574
md"## Conv & ViT Networks"

# ‚ïî‚ïê‚ï° 32baae21-b5fa-4391-9066-23436a5a2b1d
begin
    struct Conv1DChain
        chain::Chain
    end
    Flux.@layer Conv1DChain trainable = (chain)
    function (m::Conv1DChain)(x)
        x = cat(x, dims=3)
        n1, n2, n3 = size(x)
        X = reshape(x, :, 1, n2 * n3)
        X = m.chain(X)
        X = reshape(X, :, n2, n3)
        return X
    end
end

# ‚ïî‚ïê‚ï° 89599b3f-8c20-46c5-8f5c-ccbb71b26b36
function get_conv_encoder(nt, p)
    trunk = Chain(
        Conv((50,), 1 => 5, activation, ; pad=SamePad()),
        Conv((20,), 5 => 10, activation; pad=SamePad()),
        MeanPool((4,)),
        Conv((20,), 10 => 20, activation, ; pad=SamePad()),
        Conv((5,), 20 => 50, activation; pad=SamePad()),
        MeanPool((4,)),
    )
    conv_outsize = Flux.outputsize(trunk, (nt, 1); padbatch=true)
    last_layer = Dense(prod(conv_outsize) => p, activation)
    return Conv1DChain(Chain(
        trunk...,
        Flux.flatten,
        last_layer,
    ))
end

# ‚ïî‚ïê‚ï° 64430447-c267-4eec-8d38-63ccf91d82c4
function get_conv_decoder(nt, pq)
    return Conv1DChain(Chain(
        Dense(pq, nt, activation),
        Dense(nt, nt, activation),
        Conv((50,), 1 => 5, activation, ; pad=SamePad()),
        Conv((20,), 5 => 20, activation, ; pad=SamePad()),
        Conv((20,), 20 => 20, activation, ; pad=SamePad()),
        Conv((5,), 20 => 50, activation, ; pad=SamePad()),
        Conv((5,), 50 => 1, ; pad=SamePad()),
    ))
end

# ‚ïî‚ïê‚ï° 5847ea08-43ca-4c6d-a694-0017d7396f60
# function get_conv_decoder(nt, pq)
#     @assert nt % 16 == 0 "Output length nt must be divisible by 16 for DCGAN generator."
#     latent_length = div(nt, 16)
# 	nc0 = 256
#     return Conv1DChain(Chain(
#         Dense(pq, latent_length * nc0, activation),
# 		x->reshape(x, latent_length, nc0, :),
#         ConvTranspose((4,), nc0 => div(nc0, 2); stride=2, pad=1),
# 		BatchNorm(div(nc0, 2)),
# 		activation,
# 		ConvTranspose((4,), div(nc0, 2) => div(nc0, 4); stride=2, pad=1),
# 		BatchNorm(div(nc0, 4)),
# 		activation,
# 		ConvTranspose((4,), div(nc0, 4) => div(nc0, 8); stride=2, pad=1),
# 		BatchNorm(div(nc0, 8)),
# 		activation,
# 		ConvTranspose((4,), div(nc0, 8) => 1; stride=2, pad=1),
#     ))
# end

# ‚ïî‚ïê‚ï° 4fb77fae-61bb-4484-b733-82e1d1002371
begin
    struct ViT1DChain{T}
        chain::T
    end
    Flux.@layer ViT1DChain trainable = (chain)
    function (m::ViT1DChain)(x)
        x = cat(x, dims=3)
        n1, n2, n3 = size(x)
        X = reshape(x, :, 1, 1, n2 * n3)
        X = m.chain(X)
        X = Flux.flatten(X)
        X = reshape(X, :, n2, n3)
        return X
    end
end

# ‚ïî‚ïê‚ï° aeb16356-9cbb-4d07-9623-25df66e94378
function get_vit_encoder(nt, p, config=:tiny)
    vit_layers = Metalhead.vit((nt, 1); inchannels=1, pool=:mean, patch_size=(32, 1), nclasses=p, Metalhead.VIT_CONFIGS[config]...)
    return ViT1DChain(Metalhead.ViT(vit_layers))
end

# ‚ïî‚ïê‚ï° 747680b0-3469-426c-8b9e-4ab8ca04a6de
md"## Convolutional SymAE"

# ‚ïî‚ïê‚ï° bf31f347-bc9a-4bf8-a086-99dba2f6fea0
begin
    struct ConvAE
        # add parameters later
    end
    # function Conv()
    # 	return Conv()
    # end
end

# ‚ïî‚ïê‚ï° 190c8221-c5c7-48f9-b016-36c27fd4528c
function get_symae(t::ConvAE, nt, p, q, k)
    P = p * k
    dec_logvar = xpu(cat(1.0f0, dims=3))
    senc = xpu(get_conv_encoder(nt, P))
    nenc = xpu(get_conv_encoder(nt, q))
    senc_Œªlogits = xpu(Chain(Dense(P, P, activation), Dense(P, k))) # only used when k>1
    senc_Œº = xpu(Dense(P, P))
    senc_loginvvar = xpu(Dense(P, P))
    nenc_Œº = xpu(Dense(q, q))
    nenc_logœÉ = xpu(Dense(q, q))
    dec = xpu(get_conv_decoder(nt, p + q))
    return (; senc, senc_Œº, senc_loginvvar, senc_Œªlogits, nenc, nenc_Œº, nenc_logœÉ, dec, dec_logvar)
end

# ‚ïî‚ïê‚ï° 62681bba-5486-4957-8433-4258657399b8
md"## Dense SymAE"

# ‚ïî‚ïê‚ï° 0fbf59a9-74bc-479f-879c-3f72f7c76489
begin
    struct DenseAE
        flat_flag::Bool # linear decrease the width of dense layers, or not?
        nt_hidden::Int # used in the case of flat flag
        nlayers::Int # depth
    end
    function DenseAE()
        return DenseAE(false, 256, 4)
    end
end

# ‚ïî‚ïê‚ï° 0dd8d418-a664-4ecd-ac90-bab97861f9f0
function get_symae(t::DenseAE, nt, p, q, k)
    P = p * k
    senc =
        Chain(
            generate_dense_chain(
                nt,
                P,
                t.nlayers,
                activation,
                t.flat_flag,
                nt_hidden=t.nt_hidden,
            )...,
        ) |> xpu

    # instance means
    senc_Œº = Chain(Dense(P, P)) |> xpu

    # inverse variances
    senc_loginvvar = Chain(Dense(P, P)) |> xpu
    # only used when k>1
    senc_Œªlogits = xpu(Chain(Dense(P, P, activation), Dense(P, k)))

    nenc =
        Chain(
            generate_dense_chain(
                nt,
                q,
                t.nlayers,
                activation,
                t.flat_flag,
                nt_hidden=t.nt_hidden,
            )...,
        ) |> xpu

    # produce logœÉ for the nuisance encoder
    nenc_Œº = Chain(Dense(q, q)) |> xpu
    nenc_logœÉ = Chain(Dense(q, q)) |> xpu

    dec =
        Chain(
            generate_dense_chain(
                p + q,
                nt,
                t.nlayers,
                identity,
                t.flat_flag,
                nt_hidden=t.nt_hidden,
            )...,
        ) |> xpu

    dec_logvar = xpu(cat(1.0f0, dims=3))

    return (; senc, senc_Œº, senc_loginvvar, senc_Œªlogits, nenc, nenc_Œº, nenc_logœÉ, dec, dec_logvar)
end

# ‚ïî‚ïê‚ï° facd01fe-b288-437f-96dd-a8a4d9afd8fe
md"## Dense-Conv SymAE"

# ‚ïî‚ïê‚ï° 06a8d9e2-495c-4a25-8c23-527ba1b8e089
begin
    struct DenseConvAE
        flat_flag::Bool # linear decrease the width of dense layers, or not?
        nt_hidden::Int # used in the case of flat flag
        nlayers::Int # depth
    end
    function DenseConvAE()
        return DenseConvAE(false, 256, 4)
    end
end

# ‚ïî‚ïê‚ï° 4cc4fea4-2a3b-11ee-1341-d7fa7529b14a
function get_symae(t::DenseConvAE, nt, p, q, k)
    P = p * k
    senc =
        Chain(
            generate_dense_chain(
                nt,
                P,
                t.nlayers,
                activation,
                t.flat_flag,
                nt_hidden=t.nt_hidden,
            )...,
        ) |> xpu

    # instance means
    senc_Œº = Chain(Dense(P, P)) |> xpu

    # inverse variances
    senc_loginvvar = Chain(Dense(P, P)) |> xpu
    # only used when k>1
    senc_Œªlogits = xpu(Chain(Dense(P, P, activation), Dense(P, k)))

    nenc =
        Chain(
            generate_dense_chain(
                nt,
                q,
                t.nlayers,
                activation,
                t.flat_flag,
                nt_hidden=t.nt_hidden,
            )...,
        ) |> xpu

    # produce logœÉ for the nuisance encoder
    nenc_Œº = Chain(Dense(q, q)) |> xpu
    nenc_logœÉ = Chain(Dense(q, q)) |> xpu

    dec = xpu(get_conv_decoder(nt, p + q))

    dec_logvar = xpu(cat(1.0f0, dims=3))

    return (; senc, senc_Œº, senc_loginvvar, senc_Œªlogits, nenc, nenc_Œº, nenc_logœÉ, dec, dec_logvar)
end

# ‚ïî‚ïê‚ï° e00065be-8bbc-41b2-b62b-3c8ad56a5bd8
begin
    struct ViTConvAE
        config::Symbol
        ntoutput::Int
    end
    function ViTConvAE()
        return ViTConvAE(:tiny, 128)
    end
end

# ‚ïî‚ïê‚ï° a08bfd70-e464-4c5e-b1a3-860fa8cd438a
md"## ViTConv SymAE"

# ‚ïî‚ïê‚ï° 99e35014-80dc-49c6-939e-26fa0e2d7c6f
function get_symae(t::ViTConvAE, nt, p, q, k)
    P = p * k
    tencb = xpu(get_vit_encoder(nt, t.ntoutput, t.config))
    senc =
        Chain(
            generate_dense_chain(
                t.ntoutput,
                P,
                3,
                activation,
                false,
            )...,
        ) |> xpu

    # instance means
    senc_Œº = Chain(Dense(P, P)) |> xpu

    # inverse variances
    senc_loginvvar = Chain(Dense(P, P)) |> xpu

    # only used when k>1
    senc_Œªlogits = xpu(Chain(Dense(P, P, activation), Dense(P, k)))
    nenc =
        Chain(
            generate_dense_chain(
                t.ntoutput,
                q,
                3,
                activation,
                false,
            )...,
        ) |> xpu

    # produce logœÉ for the nuisance encoder
    nenc_Œº = Chain(Dense(q, q)) |> xpu
    nenc_logœÉ = Chain(Dense(q, q)) |> xpu

    dec = xpu(get_conv_decoder(nt, p + q))
    dec_logvar = xpu(cat(1.0f0, dims=3))

    return (; tencb, senc, senc_Œº, senc_loginvvar, senc_Œªlogits, nenc, nenc_Œº, nenc_logœÉ, dec, dec_logvar)
end

# ‚ïî‚ïê‚ï° eac9b092-b778-4c32-a0c5-de2eb4aa1b83
md"## AlexNet"

# ‚ïî‚ïê‚ï° 81b79f2f-9567-40c3-964e-b5a4ee96a317
function get_alex_networks(nt, p, q)
    senc =
        Chain(
            x -> reshape(x, size(x, 1), 1, size(x, 2)),
            alexnet1D(nclasses=p)) |> xpu

    # instance means
    senc_Œº = Chain(Dense(p, p)) |> xpu

    # inverse variances
    senc_loginvvar = Chain(Dense(p, p)) |> xpu

    nenc =
        Chain(
            x -> reshape(x, size(x, 1), 1, size(x, 2)),
            alexnet1D(nclasses=q)) |> xpu

    # produce logœÉ for the nuisance encoder
    nenc_Œº = Chain(Dense(q, q)) |> xpu
    nenc_logœÉ = Chain(Dense(q, q)) |> xpu

    dec =
        Chain(
            Dense(p + q, nt, activation),
            Dense(nt, nt, activation),
            x -> reshape(x, nt, 1, size(x, 2)),
            alexnet1D(nclasses=nt)
        ) |> xpu

    dec_logvar = xpu(cat(1.0f0, dims=3))

    return (; senc, senc_Œº, senc_loginvvar, nenc, nenc_Œº, nenc_logœÉ, dec, dec_logvar)
end

# ‚ïî‚ïê‚ï° 06134111-d442-4195-9c6a-43443babed8e
"""
See
https://github.com/FluxML/Metalhead.jl/blob/e662a6b307eeb77ed5004bd9a5e0232868ea85ab/src/convnets/alexnet.jl
"""
function alexnet1D(; dropout_prob=0.0, inchannels::Integer=1, nclasses::Integer=10)
    backbone = Chain(Conv((11,), inchannels => 64, activation; stride=4, pad=2),
        MaxPool((3,); stride=2),
        Conv((5,), 64 => 192, activation; pad=2),
        MaxPool((3,); stride=2),
        Conv((3,), 192 => 384, activation; pad=1),
        Conv((3,), 384 => 256, activation; pad=1),
        Conv((3,), 256 => 256, activation; pad=1),
        MaxPool((3,); stride=2))
    classifier = Chain(AdaptiveMeanPool((6,)), MLUtils.flatten,
        Dropout(dropout_prob),
        Dense(256 * 6, 1024, activation),
        Dropout(dropout_prob),
        Dense(1024, 1024, activation),
        Dense(1024, nclasses))
    return Chain(backbone, classifier)
end

# ‚ïî‚ïê‚ï° 66bddc43-ca9f-43cd-85a3-d33b11a6c033
md"## Coherent Encoder"

# ‚ïî‚ïê‚ï° b65ae9dc-dd50-4007-9894-cadef28e0552
function accumulate_Gaussians(Œº, loginvvar)
    invvar = exp.(loginvvar)
    invvarG = sum(invvar, dims=ndims(Œº) - 1)
    varG = inv.(invvarG)
    ŒºG = sum(Œº .* invvar, dims=ndims(Œº) - 1)
    cŒº = ŒºG .* varG
    return (; Œº=cŒº, logœÉ=0.5f0 .* log.(varG))
end

# ‚ïî‚ïê‚ï° 8684c192-d1b9-4821-a02e-2c7300af9b3c
begin
    struct BroadcastCoherentEnc{T1,T2,T3}
        chain::T1
        Œº::T2
        loginvvar::T3
    end
    Flux.@layer BroadcastCoherentEnc trainable = (chain, Œº, loginvvar)
    function (m::BroadcastCoherentEnc)(x)
        X = m.chain(x)
        Œº = m.Œº(X)
        loginvvar = m.loginvvar(X)
        return accumulate_Gaussians(Œº, loginvvar)
    end
end

# ‚ïî‚ïê‚ï° e9efedc1-8287-4676-ba64-a4abc77da18d
begin
    struct BroadcastCoherentEncCategorical{T1,T2,T3,T4}
        chain::T1
        Œº::T2
        loginvvar::T3
        Œªlogits::T4
    end
    Flux.@layer BroadcastCoherentEncCategorical trainable = (chain, Œº, loginvvar, Œªlogits)
    function (m::BroadcastCoherentEncCategorical)(x)
        X = m.chain(x)
        Œº = m.Œº(X)
        loginvvar = m.loginvvar(X)
        Œªlogits = m.Œªlogits(X)
        return merge(accumulate_Gaussians(Œº, loginvvar), (; Œªlogits))
    end
end

# ‚ïî‚ïê‚ï° 52dc9696-3e0b-42c7-b6cf-7a07ca3cb4dd
md"## Nuisance Encoder"

# ‚ïî‚ïê‚ï° fa646879-158a-4cbb-be0e-d375cf486ba0
begin
    struct BroadcastNuisanceEnc{T1,T2,T3}
        chain::T1
        Œº::T2
        logœÉ::T3
    end
    Flux.@layer BroadcastNuisanceEnc trainable = (chain, Œº, logœÉ)
    function (m::BroadcastNuisanceEnc)(x)
        X = m.chain(x)
        Œº = m.Œº(X)
        logœÉ = m.logœÉ(X)
        return (; Œº, logœÉ)
    end
end

# ‚ïî‚ïê‚ï° eafab001-87a7-423f-917f-1fbd46699186
md"## Decoder"

# ‚ïî‚ïê‚ï° 237ad98e-75db-41fc-b378-b895facdd8d9
begin
    struct BroadcastDec{T1,T2}
        chain::T1
        logvar::T2
    end
    Flux.@layer BroadcastDec trainable = (chain, logvar)
    function (m::BroadcastDec)(x)
        XŒº = m.chain(x)
        return XŒº, m.logvar
    end
end

# ‚ïî‚ïê‚ï° 5ed89ee8-325b-4757-b348-e6c1a3d277ad
md"## SymVAE Model"

# ‚ïî‚ïê‚ï° 04f9b328-edc8-4b1e-9a7c-79a215b1cf5f
begin
    struct SymVAE{T1,T2,T3}
        sencb::T1
        nencb::T2
        decb::T3
    end
    function SymVAE(NN, k=1)
        sencb = if (k > 1)
            BroadcastCoherentEncCategorical(NN.senc, NN.senc_Œº, NN.senc_loginvvar, NN.senc_Œªlogits)
        else
            BroadcastCoherentEnc(NN.senc, NN.senc_Œº, NN.senc_loginvvar)
        end
        nencb = BroadcastNuisanceEnc(NN.nenc, NN.nenc_Œº, NN.nenc_logœÉ)
        decb = BroadcastDec(NN.dec, NN.dec_logvar)
        model = SymVAE(sencb, nencb, decb)
    end
    function (m::SymVAE)(x, nnoise, cnoise, temperature)
        C = m.sencb(x)
        N = m.nencb(x)
        xhat, xhat_logvar = sample_q_decode(C..., N..., nnoise, cnoise, m.decb, temperature)
        return (;
            Z=(; N, C),
            X=(; xhat, xhat_logvar),
            shifts=[0f0]
        )
    end
    function (m::SymVAE)(xc, xn, nnoise, cnoise, temperature)
        C = m.sencb(xc)
        N = m.nencb(xn)
        xhat, xhat_logvar = sample_q_decode(C..., N..., nnoise, cnoise, m.decb, temperature)
        return (;
            Z=(; N, C),
            X=(; xhat, xhat_logvar),
            shifts=[0f0]
        )
    end
    # get coherent code for each element of D
    function (m::SymVAE)(D::Vector{T}, ::Val{:coherent}; args...) where {T}
        return map(D) do d
            m.sencb(d)
        end
    end
    # get nuisance code for each element of D
    function (m::SymVAE)(D::Vector{T}, ::Val{:nuisance}; args...) where {T}
        return map(D) do d
            m.nencb(d)
        end
    end
    # get coherent code for d
    function (m::SymVAE)(d, ::Val{:coherent}; args...)
        return m.sencb(d)
    end
    # get nuisance code for d
    function (m::SymVAE)(d, ::Val{:nuisance}; args...)
        return m.nencb(d)
    end
    function (m::SymVAE)(::Any, ::Val{:transform})
        return nothing
    end
    Flux.@layer SymVAE trainable = (sencb, nencb, decb)
end

# ‚ïî‚ïê‚ï° 371354f6-29e7-4227-b006-f2daacb08ce7
md"""## SymVAETrunk Model
Both coherent and nuisance encoders have a common _trunk_
"""

# ‚ïî‚ïê‚ï° 186713a3-c357-427c-9af4-6739de2d33c5
begin
    struct SymVAETrunk{T1,T2,T3,T4}
        tencb::T1
        sencb::T2
        nencb::T3
        decb::T4
    end
    function SymVAETrunk(NN, k=1)
        tencb = NN.tencb
        sencb = if (k > 1)
            BroadcastCoherentEncCategorical(NN.senc, NN.senc_Œº, NN.senc_loginvvar, NN.senc_Œªlogits)
        else
            BroadcastCoherentEnc(NN.senc, NN.senc_Œº, NN.senc_loginvvar)
        end
        sencb = BroadcastCoherentEnc(NN.senc, NN.senc_Œº, NN.senc_loginvvar)
        nencb = BroadcastNuisanceEnc(NN.nenc, NN.nenc_Œº, NN.nenc_logœÉ)
        decb = BroadcastDec(NN.dec, NN.dec_logvar)
        model = SymVAETrunk(tencb, sencb, nencb, decb)
    end
    function (m::SymVAETrunk)(x, nnoise, cnoise, temperature)
        xt = m.tencb(x)
        C = m.sencb(xt)
        N = m.nencb(xt)
        xhat, xhat_logvar = sample_q_decode(C..., N..., nnoise, cnoise, m.decb, temperature)
        return (;
            Z=(; N, C),
            X=(; xhat, xhat_logvar),
            shifts=[0f0]
        )
    end
    function (m::SymVAETrunk)(xc, xn, nnoise, cnoise, temperature)
        C = m.sencb(m.tencb(xc))
        N = m.nencb(m.tencb(xn))
        xhat, xhat_logvar = sample_q_decode(C..., N..., nnoise, cnoise, m.decb, temperature)
        return (;
            Z=(; N, C),
            X=(; xhat, xhat_logvar),
            shifts=[0f0]
        )
    end
    # get coherent code for each element of D
    function (m::SymVAETrunk)(D::Vector{T}, ::Val{:coherent}; args...) where {T}
        return map(D) do d
            m.sencb(m.tencb(d))
        end
    end
    # get nuisance code for each element of D
    function (m::SymVAETrunk)(D::Vector{T}, ::Val{:nuisance}; args...) where {T}
        return map(D) do d
            m.nencb(m.tencb(d))
        end
    end
    # get coherent code for d
    function (m::SymVAETrunk)(d, ::Val{:coherent}; args...)
        return m.sencb(m.tencb(d))
    end
    # get nuisance code for d
    function (m::SymVAETrunk)(d, ::Val{:nuisance}; args...)
        return m.nencb(m.tencb(d))
    end
    function (m::SymVAETrunk)(::Any, ::Val{:transform})
        return nothing
    end
    Flux.@layer SymVAETrunk trainable = (tencb, sencb, nencb, decb)
end

# ‚ïî‚ïê‚ï° fe87efed-9c40-4869-bdf3-cc60eb5b6436
md"### Sample Posterior and Decode"

# ‚ïî‚ïê‚ï° 76c4f167-11b5-48a3-b3b3-4fe8fd9646c1
"""
Coherent code is distributed across all the wavefield instances
"""
function sample_q_decode(cŒº, clogœÉ, nŒº, nlogœÉ, nnoise, cnoise, decoder, temperature)
    if (cnoise)
        cx = cŒº + xpu(randn(Float32, size(clogœÉ))) .* exp.(clogœÉ)
    else
        cx = cŒº
    end
    cx = dropdims(cx, dims=ndims(cŒº) - 1)
    cx = Flux.stack(fill(cx, size(nŒº, ndims(nŒº) - 1)), dims=ndims(nŒº) - 1)

    if (nnoise)
        nx = nŒº + xpu(randn(Float32, size(nlogœÉ))) .* exp.(nlogœÉ)
    else
        nx = nŒº
    end

    xhat, xhat_logvar = decoder(cat(cx, nx, dims=1))
    return xhat, xhat_logvar
end

# ‚ïî‚ïê‚ï° 78e16b27-85c3-4d4a-9238-3ec2a33c9c88
"""
Coherent code will be divided into K chunks
* Œªlog are unnormalized logits determining which chunk of the coherent code to be used for the generator (decoder)
* œÑ is the temperature: non-negative scalar As œÑ‚Üí0, the softmax becomes an argmax and the Gumbel-Softmax distribution becomes the categorical distribution. During training, we let œÑ>0 to allow gradients past the sample, then gradually anneal the temperature œÑ (but not completely to 0, as the gradients would blow up).
* if nnoise is false, then the returned Œªx will be one-hot (used after training)
"""
function sample_q_decode(cŒº, clogœÉ, Œªlogits, nŒº, nlogœÉ, nnoise, cnoise, decoder, temperature)
    if (cnoise)
        cx = cŒº + xpu(randn(Float32, size(clogœÉ))) .* exp.(clogœÉ)
    else
        cx = cŒº
    end
    cx = dropdims(cx, dims=ndims(cŒº) - 1)
    cx = Flux.stack(fill(cx, size(nŒº, ndims(nŒº) - 1)), dims=ndims(nŒº) - 1)

    if (nnoise)
        nx = nŒº + xpu(randn(Float32, size(nlogœÉ))) .* exp.(nlogœÉ)
    else
        nx = nŒº
    end

    if (nnoise)
        eps = 1f-6
        gumbel_noise = xpu(-log.(eps .+ -log.(eps .+ rand(Float32, size(Œªlogits)))))
        Œªx = softmax((Œªlogits .+ gumbel_noise) ./ temperature, dims=1)
    else
        max_indices = getindex.(dropdims(CUDA.argmax(Œªlogits, dims=1), dims=1), 1)
        Œªx = Flux.onehotbatch(max_indices, 1:size(Œªlogits, 1))  # OneHotMatrix
    end

    cx_chunks = chunk(cx, size(Œªlogits, 1), dims=1)
    Œª_chunks = chunk(Œªx, size(Œªlogits, 1), dims=1)
    cx = sum(map(cx_chunks, Œª_chunks) do c, l
        c .* l
    end)

    xhat, xhat_logvar = decoder(cat(cx, nx, dims=1))
    return xhat, xhat_logvar
end

# ‚ïî‚ïê‚ï° efde2571-4e1d-4626-9081-86d513707f5e
md"## Deterministic SymAE with Dropout"

# ‚ïî‚ïê‚ï° d74b7838-98c4-4356-8a0d-1a2388369788
# begin
#     # NOT USED
#     struct Model_Dropout{T1,T2,T3}
#         sencb::T1
#         nencb::T2
#         decb::T3
#     end
#     function (m::Model_Dropout)(x, nnoise, cnoise)
#         cx, cŒº, clogœÉ = m.sencb(x)

#         nŒº, nlogœÉ = m.nencb(x)

#         if (nnoise)
#             nx = dropout(nŒº, 0.8)
#         else
#             nx = nŒº
#         end
#         cx = dropdims(cx, dims=ndims(cŒº) - 1)
#         cx = Flux.stack(fill(cx, size(nx, ndims(nx) - 1)), dims=ndims(nx) - 1)
#         xhat, xhat_logvar = m.decb(cat(cx, nx, dims=1))

#         return (;
#             Z=(; N=(; Œº=nŒº, logœÉ=nlogœÉ), C=(; Œº=cŒº, logœÉ=clogœÉ)),
#             X=(; xhat, xhat_logvar),
#         )
#     end
#     Flux.@layer Model_Dropout trainable = (sencb, nencb, decb)
# end

# ‚ïî‚ïê‚ï° 95660df0-088b-49f3-b875-fca19a82d024
md"""## Spatial Transformer Model
Wrap any SymVAE model with a spatial transformer
 - First, predict time shifts with transformerb
 - Then, apply shifts
 - Then, apply SymVAE model
 - Last, apply inv_shifts
"""

# ‚ïî‚ïê‚ï° c49e3d81-27ba-4a4f-870a-ae218a505dd0
begin
    struct Spatial_Transformer{T1,T2,T3}
        symvae::T1
        transformerb::T2
        sampling_grid::T3
    end
    function (m::Spatial_Transformer)(x, nnoise::Bool, cnoise::Bool, temperature)
        S = m.transformerb(x)
        xt = shift_traces_Fourier(x, S.shifts, m.sampling_grid)
        output = m.symvae(xt, nnoise, cnoise, temperature)
        xhat = shift_traces_Fourier(output.X.xhat, S.inv_shifts, m.sampling_grid)
        return (; X=(; xhat, xshifted=xt, xhat_logvar=output.X.xhat_logvar), Z=output.Z, shifts=S.shifts)
    end
    function (m::Spatial_Transformer)(xc, xn, nnoise::Bool, cnoise::Bool, temperature)
        Sc = m.transformerb(xc)
        Sn = m.transformerb(xn)
        xct = shift_traces_Fourier(xc, Sc.shifts, m.sampling_grid)
        xnt = shift_traces_Fourier(xn, Sn.shifts, m.sampling_grid)
        output = m.symvae(xct, xnt, nnoise, cnoise, temperature)
        xhat = shift_traces_Fourier(output.X.xhat, Sn.inv_shifts, m.sampling_grid)
        return (; X=(; xhat, xshifted=xt, xhat_logvar=output.X.xhat_logvar), Z=output.Z, shifts=S.shifts)
    end
    # estimate either coherent or nuisance code after applying transformer, for each element of D
    function (m::Spatial_Transformer)(D::Vector{T}, code_type::Union{Val{:coherent},Val{:nuisance}}; apply_transformer=true) where {T}
        Dshifted = if (apply_transformer)
            m(D, Val(:transform))
        else
            D
        end
        return m.symvae(Dshifted, code_type)
    end
    # estimate either coherent or nuisance code after applying transformer
    function (m::Spatial_Transformer)(d, code_type::Union{Val{:coherent},Val{:nuisance}}; apply_transformer=true)
        dshifted = if (apply_transformer)
            m(d, Val(:transform))
        else
            d
        end
        return m.symvae(dshifted, code_type)
    end
    function (m::Spatial_Transformer)(D::Vector{T}, ::Val{:transform}) where {T}
        return map(D) do d
            S = m.transformerb(d)
            d = shift_traces_Fourier(d, S.shifts, m.sampling_grid)
        end
    end
    function (m::Spatial_Transformer)(d, ::Val{:transform})

        S = m.transformerb(d)
        return shift_traces_Fourier(d, S.shifts, m.sampling_grid)

    end
    # sampling grid is not trainable
    Flux.@layer Spatial_Transformer trainable = (symvae, transformerb)
    # if something is not available, search symvae model
    function Base.getproperty(m::Spatial_Transformer, s::Symbol)
        if (s in propertynames(m))
            return getfield(m, s)
        else
            return getfield(m.symvae, s)
        end
    end
end

# ‚ïî‚ïê‚ï° 5731aea5-af70-4dc3-a505-2f48fce02e8e
md"""
### SpatialTransformer
"""

# ‚ïî‚ïê‚ï° 56055fa2-8f96-4b43-b1eb-2cd5a9cbadeb
begin
    """
    Spatial State Transformer 
    """
    struct BroadcastSpatialStateTransformer{T1}
        chain::T1
    end
    Flux.@layer BroadcastSpatialStateTransformer trainable = (chain)
    function (m::BroadcastSpatialStateTransformer)(x)
        X = cat(x, dims=3)
        s1 = m.chain(X)
        s = mean(s1, dims=ndims(s1) - 1)
        s = dropdims(s, dims=ndims(s) - 1)
        s = Flux.stack(fill(s, size(s1, ndims(s1) - 1)), dims=ndims(s1) - 1)
        return (; shifts=s, inv_shifts=-1.0f0 .* s)
    end
end

# ‚ïî‚ïê‚ï° 90e69a62-b340-45d6-944e-cb56f6f46ca6
begin
    """
    Spatial Transformer 
    """
    struct BroadcastSpatialTransformer{T1}
        chain::T1
    end
    Flux.@layer BroadcastSpatialTransformer trainable = (chain)
    function (m::BroadcastSpatialTransformer)(x)
        X = cat(x, dims=3)
        s = m.chain(X)
        return (; shifts=s, inv_shifts=-1.0f0 .* s)
    end
end

# ‚ïî‚ïê‚ï° e80dd767-72ef-410b-b7a2-38e0545a5df3
function get_dense_transformer(nt; nt_hidden=nt)
    transformer =
        Chain(
            Dense(nt, nt_hidden, activation),
            Dense(nt_hidden, nt_hidden, activation),
            Dense(nt_hidden, 1, init=zeros),
        ) |> xpu
    return transformer
end

# ‚ïî‚ïê‚ï° 1f139691-e19f-41e5-8113-3cc00e8fe2b8
#===
        code for full spatial transformer (commented for now, as only Fourier shifts is used)
              #         shifts = cat(
              #             cat(
              #                 xpu(ones(Float32, 1, 1, 1, n2 * n3)),
              #                 reshape(shifts1, 1, 1, 1, n2 * n3),
              #                 dims = 2,
              #             ),
              #             xpu(zeros(Float32, 1, 2, 1, n2 * n3)),
              #             dims = 1,
              #         )

              #         inv_shifts = cat(
              #             cat(
              #                 xpu(ones(Float32, 1, 1, 1, n2 * n3)),
              #                 -1.0f0 * reshape(shifts1, 1, 1, 1, n2 * n3),
              #                 dims = 2,
              #             ),
              #             xpu(zeros(Float32, 1, 2, 1, n2 * n3)),
              #             dims = 1,
              #         )
              # return (; shifts, inv_shifts, shiftsŒº = sŒº)
        ===#

# ‚ïî‚ïê‚ï° 825dda0d-6472-405c-b149-5c4d2202963f
# """
# code for spatial transformer (commented for now, as only Fourier shifts is used)
# shift traces with localization net
# - input_traces have size (nt, nr)
# - localization_net returns the time shifts (nr)
# - uses global variable sampling_grid
# """
# function shift_traces_grid_sample(input_traces, shifts, sampling_grid)
#     S = Flux.stack(fill(sampling_grid, size(shifts, 4)), dims=4)
#     grids = batched_mul(shifts, S)
#     input_traces1 =
#         reshape(input_traces, size(input_traces, 1), 1, 1, prod(size(input_traces)[2:end]))
#     output_traces = grid_sample(input_traces1, grids; padding_mode=:zeros)
#     return reshape(output_traces, size(input_traces))
# end

# ‚ïî‚ïê‚ï° 8abc3a6d-d2f5-4527-a828-793364706fa5

"""
shift traces using Fourier Interpolation
"""
function shift_traces_Fourier(input_traces, shifts, sampling_grid)
    x_fft = fouriertransform1D(input_traces)
    S = cat(sampling_grid, dims=ndims(shifts))
    E = exp.(S .* shifts)
    output_traces_fft = x_fft .* E
    output_traces = inversefouriertransform1D(output_traces_fft)
    return reshape(output_traces, size(input_traces))
end


# ‚ïî‚ïê‚ï° 84d56fa3-50de-48ad-8e07-dfaecc1cfdf3
function fouriertransform1D(ùê±::AbstractArray)
    return fft(ùê±, 1) # perform fft along first dimension
end

# ‚ïî‚ïê‚ï° 86a120ae-8865-4e99-a028-f567f3c1bbad
function inversefouriertransform1D(ùê±_fft::AbstractArray)
    return real(ifft(ùê±_fft, 1)) # perform ifft along first dimension
end

# ‚ïî‚ïê‚ï° f4238f8e-3596-4c98-a64e-477c3aa2b054
md"## Nuisance Optimization Model"

# ‚ïî‚ïê‚ï° a48d23b6-86d6-4232-a1b9-300e65b264ff
begin
    """
    Select only Œº and logœÉ from coherent codes
    Depending on kopt, select respective chunk of the coherent code
    """
    function batch_coherent_codes(vec::Vector{<:NamedTuple}, kopt)
        k = if (:Œªlogits ‚àà keys(vec[1]))
            size(vec[1].Œªlogits, 1)
        else
            1
        end
        merged = (; Œº=cat(getfield.(vec, :Œº)..., dims=3), logœÉ=cat(getfield.(vec, :logœÉ)..., dims=3))
        # select kopt chunk
        return map(merged) do m
            getindex(chunk(m, k, dims=1), kopt)
        end
    end
    function batch_coherent_codes(C::NamedTuple, kopt)
        k = if (:Œªlogits ‚àà keys(C))
            size(C.Œªlogits, 1)
        else
            1
        end
        merged = (; Œº=C.Œº, logœÉ=C.logœÉ)
        # select kopt chunk
        return map(merged) do m
            getindex(chunk(m, k, dims=1), kopt)
        end
    end
end

# ‚ïî‚ïê‚ï° 84aa58d3-115b-4d2d-a798-fc936f5bb2ca
begin
    struct Model_Optimal_Nuisance{T1,T2,T3}
        nuisance_codes::T1
        model::T2
        shifted_init::T3
        kopt::Int
    end
    function (m::Model_Optimal_Nuisance)(coherent_codes)
        coherent_codes_batched = batch_coherent_codes(coherent_codes, m.kopt)
        nx = cat(m.nuisance_codes, dims=3)
        xhat, _ = sample_q_decode(coherent_codes_batched..., nx, nothing, false, false, m.model.decb, 0f0)
        xhat = xhat .- mean(xhat, dims=1) # NECESSARY?
        C_all = m.model(reshape(xhat, size(xhat, 1), 1, size(xhat, 2) * size(xhat, 3)), Val(:coherent), apply_transformer=false)
		C_all_batched = batch_coherent_codes(C_all, m.kopt)
		cŒº_all = C_all_batched.Œº
		clogœÉ_all = C_all_batched.logœÉ
        cŒº_all = reshape(cŒº_all, size(cŒº_all, 1), size(xhat, 2), size(xhat, 3))
        clogœÉ_all = reshape(clogœÉ_all, size(clogœÉ_all, 1), size(xhat, 2), size(xhat, 3))
        return xhat, cŒº_all, clogœÉ_all
    end
    function (m::Model_Optimal_Nuisance)(nuisance_codes, C)
        copyto!(m.nuisance_codes, nuisance_codes)
        return m(C)
    end
    Flux.@layer Model_Optimal_Nuisance trainable = (nuisance_codes)
end

# ‚ïî‚ïê‚ï° a46ce69a-3081-4e86-b9eb-c773c772f459
"""
Create an instance of Model_Optimal_Nuisance
"""
function get_Model_Optimal_Nuisance(para, model; kopt=1, init=nothing)
    initial_nuisance_codes, shifted_init = if (init === nothing)
        xpu(randn(para.q)), nothing
    else
        output = model(init, Val(:nuisance))
        output.Œº, model(init, Val(:transform))
    end
    return Model_Optimal_Nuisance(xpu(initial_nuisance_codes), model, shifted_init, kopt)
end

# ‚ïî‚ïê‚ï° 2b3bf9d1-87cc-4884-b3d7-f1b81f6769dc
"""
Return KL divergence between accumulated coherent information and coherent information in the instances generated using optimal nuisance model
"""
function loss_kl_Qc_accumulated(optimal_nuisance_model, C, alpha; p=1, Bref=1f0, Cref=1f0)
    virtualdata, cŒº_all, clogœÉ_all, = optimal_nuisance_model(C)
	Cbatched = batch_coherent_codes(C, optimal_nuisance_model.kopt)
    B = map(unstack(cŒº_all, dims=2), unstack(clogœÉ_all, dims=2)) do cŒº1, clogœÉ1
        kl_divergence_multivariate_gaussians(Cbatched.Œº, Cbatched.logœÉ, cŒº1, clogœÉ1)
        # neg_logpdf_gaussian(cŒº1, cŒº, clogœÉ)
    end
    B = sum.(B)
    virtualdata1 = normalise(virtualdata, dims=1)
    return sum(B) / Bref + alpha * norm(virtualdata1, p) / Cref, B, norm(virtualdata1, p)
end

# ‚ïî‚ïê‚ï° afb6c675-0ef8-445c-a204-795e300c8589
function loss_kl_Qc_accumulated(optimal_nuisance_model, coherent_codes::Vector{T}, alpha; p=1, Bref=1f0, Cref=1f0) where {T}

    virtualdata, cŒº_all, clogœÉ_all, = optimal_nuisance_model(coherent_codes)
    coherent_codes_batched = batch_coherent_codes(coherent_codes, optimal_nuisance_model.kopt)

    cŒº_in = coherent_codes_batched.Œº
    cŒº_in = dropdims(cŒº_in, dims=ndims(cŒº_in) - 1)
    cŒº_in = Flux.stack(fill(cŒº_in, size(cŒº_all, ndims(cŒº_all) - 1)), dims=ndims(cŒº_all) - 1)

    clogœÉ_in = coherent_codes_batched.logœÉ
    clogœÉ_in = dropdims(clogœÉ_in, dims=ndims(clogœÉ_in) - 1)
    clogœÉ_in = Flux.stack(fill(clogœÉ_in, size(clogœÉ_all, ndims(clogœÉ_all) - 1)), dims=ndims(clogœÉ_all) - 1)

    B = kl_divergence_multivariate_gaussians(cŒº_in, clogœÉ_in, cŒº_all, clogœÉ_all)
    # B = neg_logpdf_gaussian(cŒº_all, cŒº_in, clogœÉ_in)

    virtualdata1 = normalise(virtualdata, dims=1)
    return sum(B) / Bref + alpha * norm(virtualdata1, p) / Cref, B, norm(virtualdata1, p)
end

# ‚ïî‚ïê‚ï° 88e02d85-85df-4913-be59-1fc836f39114
"""
Same as above, but elasticnet type regularization to minimize noise
"""
function loss_kl_Qc_accumulated_elasticnet(optimal_nuisance_model, C, alpha)
    virtualdata, cŒº_all, clogœÉ_all, = optimal_nuisance_model(C)
    B = map(unstack(cŒº_all, dims=3), unstack(clogœÉ_all, dims=3)) do cŒº1, clogœÉ1
        kl_divergence_multivariate_gaussians(C.Œº, C.logœÉ, cŒº1, clogœÉ1)
        # neg_logpdf_gaussian(cŒº1, cŒº, clogœÉ)
    end
    return sum(B) + alpha[1] * (alpha[2] * norm(virtualdata, 1) + (1 - alpha[2]) * (norm(virtualdata, 2))^2), B
end

# ‚ïî‚ïê‚ï° fafede49-59df-47e0-a870-74b946a36af5
# function loss_kl_Qc_accumulated(optimal_nuisance_model, coherent_codes, alpha)
#     Bdata = map(coherent_codes) do coherent_code
#         virtualdata, cŒº_all, clogœÉ_all, =
#             optimal_nuisance_model(coherent_code.cŒº, coherent_code.clogœÉ)
#         B = map(unstack(cŒº_all, dims=3), unstack(clogœÉ_all, dims=3)) do cŒº1, clogœÉ1
#             kl_divergence_multivariate_gaussians(
#                 coherent_code.cŒº,
#                 coherent_code.clogœÉ,
#                 cŒº1,
#                 clogœÉ1,
#             )
#             # bhattacharyya_distance(optimal_nuisance_model.cŒº,optimal_nuisance_model.clogœÉ, cŒº1, clogœÉ1)
#         end
#         return mean(B), B, virtualdata
#     end

#     return mean(first.(Bdata)) + alpha * mean(norm.(getindex.(Bdata, 3), 1)), mean(getindex.(Bdata, 2))

# end

# ‚ïî‚ïê‚ï° a85b6958-d894-45cc-86c6-933fba757e1c
function loss_kl_Qc_accumulated(nuisance_codes, optimal_nuisance_model, C, alpha)
    copyto!(optimal_nuisance_model.nuisance_codes, nuisance_codes)
    return loss_kl_Qc_accumulated(optimal_nuisance_model, C, alpha)
end

# ‚ïî‚ïê‚ï° 74c8e79f-b1c8-484b-86bf-65c2a2831b53
"""
"""
function optimize_nuisance_code_black_box_optim(d, para, model; MaxTime=10.0)
    coherent_codes = model(d, Val(:coherent))
    optimal_nuisance_model = get_Model_Optimal_Nuisance(para, model, init=randobs(d))
    loss(x) = Float64(
        loss_kl_Qc_accumulated(
            x,
            optimal_nuisance_model,
            coherent_codes
        )[1],
    )
    result = bboptimize(
        loss;
        NumDimensions=para.q,
        SearchRange=(-10.0, 10.0),
        MaxTime=MaxTime,
        MaxSteps=-1,
        TraceMode=:silent,
        #inDeltaFitnessTolerance = 0.01
    )
    return optimal_nuisance_model(
        best_candidate(result),
        coherent_codes.cŒº,
        coherent_codes.clogœÉ,
    )[1],
    result
end

# ‚ïî‚ïê‚ï° 073c77d1-7598-45d3-858d-9222f2e4c590
"""
"""
function optimize_nuisance_code_metaheuristics(d, para, model; MaxTime=10)
    coherent_codes = model([d], Val())[1]

    _, _, ideal_seismogram_ids = kl_Qc_accumulated(para, model, [d], 255, 1)
    ideal_seismograms = mapreduce(hcat, ideal_seismogram_ids) do ideal_seismogram_id
        d[:, ideal_seismogram_id]
    end

    optimal_nuisance_model =
        get_Model_Optimal_Nuisance(para, model, init=ideal_seismograms)
    function loss(X)
        if (ndims(X) == 2)
            x = permutedims(X, (2, 1))
        elseif (ndims(X) == 3)
            x = permutedims(X, (2, 1, 3))
        else
            x = X
        end
        L = loss_kl_Qc_accumulated(
            x,
            optimal_nuisance_model,
            coherent_codes
        )[2]
        if (ndims(X) == 1)
            return Float64(L[1])
        else
            return Float64.(L[1:size(X, 1)])
        end
    end
    options = Options(
        f_calls_limit=0,
        time_limit=MaxTime,
        parallel_evaluation=true,
        iterations=1000,
    )
    bounds = boxconstraints(lb=-Inf * ones(para.q), ub=Inf * ones(para.q))
    algo = GA(
        options=options,
        mutation=Metaheuristics.PolynomialMutation(; bounds),
        crossover=SBX(; bounds),
        environmental_selection=GenerationalReplacement(),
    )
    # algo = ECA(options = options)

    initial_nuisances =
        Float64.(
            cpu(
                dropdims(
                    permutedims(optimal_nuisance_model.nuisance_codes, (2, 1, 3)),
                    dims=3,
                ),
            )
        )
    set_user_solutions!(algo, initial_nuisances[1:100, :], loss)
    result = optimize(loss, bounds, algo)

    return optimal_nuisance_model(
        minimizer(result),
        coherent_codes.cŒº,
        coherent_codes.clogœÉ,
    )[1],
    result
end

# ‚ïî‚ïê‚ï° c4de28ea-5af6-4c66-9955-a5d168833036
"""
Train to update nuisance codes
"""
function update_nuisance_codes(
    optimal_nuisance_model,
    D::Vector{T};
    nepochs=100,
    learning_rate=0.01,
    alpha=0.0,
    p=1
) where {T}
    opt_state = Flux.setup(Optimisers.AdamW(learning_rate), optimal_nuisance_model)
    loss_history =
        Array{Float32,3}(undef, nepochs, size(optimal_nuisance_model.nuisance_codes, 2), length(D))
    coherent_codes = optimal_nuisance_model.model(D, Val(:coherent))
    xsave = optimal_nuisance_model(coherent_codes)
    _, Brefall, Cref = loss_kl_Qc_accumulated(optimal_nuisance_model, coherent_codes, alpha; p=p)
    @progress for epoch = 1:nepochs

        result = Flux.withgradient(optimal_nuisance_model) do m
            J, B, _ = loss_kl_Qc_accumulated(m, coherent_codes, alpha; p=p, Bref=sum(Brefall), Cref=Cref)
            J, B  # here B is an auxiliary output
        end
        #             grads = Flux.gradient(
        #                 (m, Œº, logœÉ) -> loss_kl_Qc_accumulated(m, Œº, logœÉ, alpha)[1],
        #                 optimal_nuisance_model,
        #                 coherent_code.cŒº,
        #                 coherent_code.clogœÉ,
        #             )[1]
        # according to the corresponding gradient:
        optimal_nuisance_model.nuisance_codes .= optimal_nuisance_model.nuisance_codes .- learning_rate .* result.grad[1].nuisance_codes

        B = cpu(result.val[2])
        for j = 1:length(D)
            for i = 1:size(B, 2)
                loss_history[epoch, i, j] = B[1, i, j]
            end
        end
        if (mod(epoch, 10) == 0)
            @info (; epoch=epoch, loss=mean(loss_history[epoch, :, :]))
        end
    end
    xnew = optimal_nuisance_model(coherent_codes)
    return (; xsave, xnew, loss_history)
end

# ‚ïî‚ïê‚ï° b2e5505d-819d-4a48-b763-d81b4065b32b
"""
Train to update nuisance codes
"""
function update_nuisance_codes(
    optimal_nuisance_model,
    d;
    nepochs=100,
    learning_rate=0.01,
    alpha=0.0,
    p=1
)
    opt_state = Flux.setup(Optimisers.AdamW(learning_rate), optimal_nuisance_model)
    loss_history =
        Matrix{Float32}(undef, nepochs, size(optimal_nuisance_model.nuisance_codes, 2))
    coherent_code = optimal_nuisance_model.model(d, Val(:coherent))
    xsave = optimal_nuisance_model(coherent_code)

    _, Brefall, Cref = loss_kl_Qc_accumulated(optimal_nuisance_model, coherent_code, alpha; p=p)

    @progress for epoch = 1:nepochs

        result = Flux.withgradient(optimal_nuisance_model) do m
            J, B, _ = loss_kl_Qc_accumulated(m, coherent_code, alpha; p=p, Bref=sum(Brefall), Cref=Cref)
            J, B  # here B is an auxiliary output
        end
        #             grads = Flux.gradient(
        #                 (m, Œº, logœÉ) -> loss_kl_Qc_accumulated(m, Œº, logœÉ, alpha)[1],
        #                 optimal_nuisance_model,
        #                 coherent_code.cŒº,
        #                 coherent_code.clogœÉ,
        #             )[1]
        # according to the corresponding gradient:
        optimal_nuisance_model.nuisance_codes .= optimal_nuisance_model.nuisance_codes .- learning_rate .* result.grad[1].nuisance_codes
        # use B
        for i = 1:length(result.val[2])
            loss_history[epoch, i] = result.val[2][i]
        end
        if (mod(epoch, 10) == 0)
            @info (; epoch=epoch, loss=mean(loss_history[epoch, :]))
        end
    end
    xnew = optimal_nuisance_model(coherent_code)
    return (; xsave, xnew, loss_history)
end

# ‚ïî‚ïê‚ï° b3428bd8-c1ec-4e48-97b0-3dbde763292b
function get_coherent_information(para, model, Doptim::T, Dnuisance::T; N=10, nepochs=100, alpha=0.1, learning_rate=0.001, initialize_within_state=false, p=1, kopt=1) where {T}

    Ideal_seismograms = cat(map(Doptim) do doptim
            if (initialize_within_state)
                DN = [doptim]
            else
                DN = Dnuisance
            end
            kl_Qcs, ideal_pixel_ids, ideal_seismogram_ids = kl_Qc_accumulated(para, model, DN, N, doptim, kopt, 0.0)

            ideal_seismograms = mapreduce(hcat, ideal_pixel_ids, ideal_seismogram_ids) do ideal_pixel_id, ideal_seismogram_id
                DN[ideal_pixel_id][:, ideal_seismogram_id]
            end
            return ideal_seismograms
        end..., dims=3)

    optimal_nuisance_model = get_Model_Optimal_Nuisance(
        para,
        model,
        init=Ideal_seismograms,
        kopt=kopt
    )

    optimal_nuisance_result = update_nuisance_codes(optimal_nuisance_model, Doptim; nepochs=nepochs, learning_rate=learning_rate, alpha=alpha, p=p)


    optim_nuisance_loss_history = optimal_nuisance_result.loss_history

    coherent_codes_all = model(Doptim, Val(:coherent))

    xhat, _, _ = optimal_nuisance_model(coherent_codes_all)
    output = cpu(unstack(xhat, dims=3))
    # @show norm(output), norm(optimal_nuisance_model.shifted_init)
    return output, Ideal_seismograms, optim_nuisance_loss_history, optimal_nuisance_model.shifted_init
end

# ‚ïî‚ïê‚ï° d62474f6-48fb-49fe-919b-c4373135067c
"""
First, get optimal nuisance codes and output coherent information in the data space.
# Arguments
- `doptim`: the KL for this state will be minimized
- `Dnuisance`: initial nuisances will be selected from these states
- `Doutput`: after optimization, the coherent information from these states will be output
- `N`: number of initial nuisance codes
"""
function get_coherent_information(para, model, doptim::T, Dnuisance::Vector{T}, Doutput::Vector{T}; N=10, nepochs=100, alpha=0.1, learning_rate=0.001, p=1, kopt=1) where {T}

    kl_Qcs, ideal_pixel_ids, ideal_seismogram_ids = kl_Qc_accumulated(para, model, Dnuisance, N, doptim, kopt, 0.0)

    ideal_seismograms = mapreduce(hcat, ideal_pixel_ids, ideal_seismogram_ids) do ideal_pixel_id, ideal_seismogram_id
        Dnuisance[ideal_pixel_id][:, ideal_seismogram_id]
    end


    # optimal_nuisance_results = map(1:size(ideal_seismograms,2)) do I
    optimal_nuisance_model = get_Model_Optimal_Nuisance(
        para,
        model,
        init=ideal_seismograms,
        kopt=kopt,
    )
    optimal_nuisance_result = update_nuisance_codes(optimal_nuisance_model, doptim; nepochs=nepochs, learning_rate=learning_rate, alpha=alpha, p=p)
    # return  optimal_nuisance_model, optimal_nuisance_result		
    # end

    optim_nuisance_loss_history = optimal_nuisance_result.loss_history
    # hcat([o[2].loss_history for o in optimal_nuisance_results]...)

    coherent_codes_all = model(Doutput, Val(:coherent))

    output = map(coherent_codes_all) do C
        xhat, _, _ = optimal_nuisance_model(C)
        # 	Xhat = []
        # 	for I in 1:N
        # 		xhat, _, _ = optimal_nuisance_results[I][1](C.cŒº, C.clogœÉ)
        # 		push!(Xhat, cpu(vec(xhat)))
        # 	end
        # 	return hcat(Xhat...)
        return cpu(dropdims(xhat, dims=3))
    end

    return output, ideal_seismograms, optim_nuisance_loss_history, optimal_nuisance_model.shifted_init
end

# ‚ïî‚ïê‚ï° ab3f0de4-3e7e-4d5f-aa1a-25fe24a52b38
md"## Losses"

# ‚ïî‚ïê‚ï° f5e6cf15-1072-4037-9a96-91db93e730f0
"""
Loss for Variational SymAE
"""
function loss_sym_vae(model, x, beta, gamma, temperature)
    result = model(x, true, true, temperature)
    neg_llh =
        0.5f0 *
        sum(@. (abs2(result.X.xhat - x) / exp(result.X.xhat_logvar)) + result.X.xhat_logvar)

    kl = sum(map(result.Z, beta) do z, b
        get_kl(z..., b...)
    end)
    spatial_transformer_norm = norm(result.shifts, 2)
    neg_elbo = neg_llh + kl + gamma * spatial_transformer_norm
    return (; neg_elbo=neg_elbo, neg_llh, kl, spatial_transformer_norm, gamma)
end

# ‚ïî‚ïê‚ï° d966211f-012e-45f2-b9ae-abf599666edf
begin
    function get_kl(Œº, logœÉ, beta)
        return beta * kl_divergence_multivariate_gaussian(Œº, logœÉ)
    end
    function get_kl(Œº, logœÉ, beta, betadummy)
        return get_kl(Œº, logœÉ, beta)
    end
end

# ‚ïî‚ïê‚ï° 97b37ee3-e87b-4942-9d9a-22cffc88ab9d
function get_kl(Œº, logœÉ, Œªlogits, betac, betaŒª)
    prior = focused_categorical_prior(size(Œªlogits, 1))
    return betac * kl_divergence_multivariate_gaussian(Œº, logœÉ) +
           betaŒª * kl_divergence_categorial_distributions(Œªlogits, prior)
end

# ‚ïî‚ïê‚ï° 6d34151a-b539-4eda-995a-b7f873719a4c
"""
Reconstruction Loss (like deterministic AE)
"""
function loss_mse(model, x)
    result = model(x, false, false, 0f0)
    return Flux.mse(result.X.xhat, x)
end

# ‚ïî‚ïê‚ï° 4ec8578c-a202-4a3d-9425-60bf623a3a02
"""
    # x: point where log-pdf is evaluated (vector)
    # mean: mean vector of the Gaussian
    # log_std: log of standard deviations (vector)
"""
function neg_logpdf_gaussian(x, mean, log_std)
    # d = length(x)
    log_det = sum(log_std, dims=1)
    squared_term = sum(((x .- mean) ./ exp.(log_std)) .^ 2, dims=1)

    neg_log_pdf = @. log_det + 0.5 * squared_term
    return neg_log_pdf
end

# ‚ïî‚ïê‚ï° 0db6b854-ef75-46c0-8e19-efd8faa037bb
"""
create a probability vector that puts almost all the mass on the first class
"""
function focused_categorical_prior(K::Int, sharpness=2.0)
    return softmax(xpu(cat([i == 1 ? sharpness : -sharpness for i in 1:K], dims=3)))
end


# ‚ïî‚ïê‚ï° 41b5d143-6a0f-4f4c-8e62-8483d9e0d5f6
"""
KL divergence between two categorical distributions
# Arguments
- `logits`: logits unnormalized
- `prior`: prior 
"""
function kl_divergence_categorial_distributions(logits, prior)
    Œª = Flux.softmax(logits; dims=1)
    Œª = clamp.(Œª, 0.0001f0, 1.0f0) # avoid log(0) in posterior
    prior = clamp.(prior, 0.0001f0, 1.0f0)  # avoid log(0) in posterior
    kl = @. (Œª * (log(Œª) - log(prior)))
    return sum(kl)
end

# ‚ïî‚ïê‚ï° e57556e8-b287-4bc5-9ea1-4f68948eccf2
"""
    kl_divergence_multivariate_gaussians(mean1, log_std1, mean2, log_std2)

Compute the Kullback-Leibler (KL) divergence between two multivariate Gaussian distributions.

# Arguments
- `mean1`: The mean of the first Gaussian distribution.
- `log_std1`: The log standard deviation of the first Gaussian distribution.
- `mean2`: The mean of the second Gaussian distribution.
- `log_std2`: The log standard deviation of the second Gaussian distribution.

# Returns
The KL divergence between the two Gaussian distributions.
"""
function kl_divergence_multivariate_gaussians(mean1, log_std1, mean2, log_std2)
    kl1 = @. (exp(2.0f0 * log_std1) / exp(2.0f0 * log_std2) + abs2(mean1 - mean2) / exp(2.0f0 * log_std2) - 1.0f0 - 2.0f0 * log_std1 + 2.0f0 * log_std2)
    kl = 0.5f0 .* sum(kl1, dims=1)
    return kl
end

# ‚ïî‚ïê‚ï° 6e7c70c8-cffe-4b30-85b4-5942fbb60da8
"""
    js_divergence_multivariate_gaussians(mean1, log_std1, mean2, log_std2)

Compute the Jensen-Shannon (JS) divergence between two multivariate Gaussian distributions.

# Arguments
- `mean1`: The mean of the first Gaussian distribution.
- `log_std1`: The log standard deviation of the first Gaussian distribution.
- `mean2`: The mean of the second Gaussian distribution.
- `log_std2`: The log standard deviation of the second Gaussian distribution.

# Returns
The JS divergence between the two Gaussian distributions.
"""
function js_divergence_multivariate_gaussians(mean1, log_std1, mean2, log_std2)
    js =
        0.5 * (
            kl_divergence_multivariate_gaussians(mean1, log_std1, mean2, log_std2) +
            kl_divergence_multivariate_gaussians(mean2, log_std2, mean1, log_std1)
        )
    return js
end

# ‚ïî‚ïê‚ï° e46630eb-5e29-4c5e-b792-0f7ca0af0ff0
"""
    hellinger_distance_multivariate_gaussians(mean1, log_sigma1, mean2, log_sigma2)
The Hellinger distance between two multivariate Gaussian distributions
"""
function hellinger_distance_multivariate_gaussians(meanX, logœÉ1, meanY, logœÉ2)
    œÉ1 = exp.(2.0f0 * logœÉ1)
    œÉ2 = exp.(2.0f0 * logœÉ2)

    detX = prod(œÉ1)
    detY = prod(œÉ2)
    covXY = (œÉ1 .+ œÉ2) / 2.0f0
    detXY = prod(covXY)

    # Compute the exponent term
    diff = meanX .- meanY
    covXY_inverted = 1 ./ covXY  # Since covXY is diagonal, inversion is element-wise
    exponent_term = exp(-0.125 * sum((diff .^ 2) .* covXY_inverted))

    # Compute the Hellinger distance
    dist = 1.0 - (fourthroot(detX) * fourthroot(detY) / sqrt(detXY)) * exponent_term

    return dist
end

# ‚ïî‚ïê‚ï° 361ead1b-3fe3-4ae2-b018-2c6904d0f889
"""
    kl_divergence_multivariate_gaussian(mean1, log_std1)

Compute the Kullback-Leibler (KL) divergence between two multivariate Gaussian distributions.

# Arguments
- `mean1`: The mean of the first Gaussian distribution.
- `log_std1`: The log standard deviation of the first Gaussian distribution.

# Returns
The KL divergence between the two Gaussian distributions.
"""
function kl_divergence_multivariate_gaussian(mean1, log_std1)
    return 0.5f0 * sum(@. (exp(2.0f0 * log_std1) + abs2(mean1) - 1.0f0 - 2.0f0 * log_std1))
end

# ‚ïî‚ïê‚ï° 4e527961-5734-4294-9f3c-e2aa8314eef6
"""
Compute the Bhattacharyya distance between two Gaussian distributions.

Parameters:
- mean1: The mean of the first Gaussian distribution.
- log_std1: The log standard deviation of the first Gaussian distribution.
- mean2: The mean of the second Gaussian distribution.
- log_std2: The log standard deviation of the second Gaussian distribution.

Returns:
- bd: The Bhattacharyya distance between the two Gaussian distributions.
"""
function bhattacharyya_distance(cŒº1, clogœÉ1, cŒº2, clogœÉ2)
    # Bhattacharya Distance
    cvar1 = @. exp(2.0f0 * clogœÉ1)
    cvar2 = @. exp(2.0f0 * clogœÉ2)
    Dvar = 0.5f0 * (sum(@. 2.0f0 * clogœÉ1) + sum(@. 2.0f0 * clogœÉ2))
    cvarmean = @. 0.5f0 * (cvar1 + cvar2)
    Nvar = sum(@. log.(cvarmean))
    return sum(@. abs2(cŒº1 - cŒº2) / cvarmean) / 8.0f0 + 0.5f0 * (Nvar - Dvar)

    # # Convert log standard deviations to standard deviations
    # std1 = exp.(log_std1)
    # std2 = exp.(log_std2)

    # # Compute the Bhattacharyya distance
    # bd = 0.5 * sum(@. ((mean1 - mean2)^2 / (std1^2 + std2^2) + log((std1 * std2) / sqrt(std1^2 + std2^2))))
    # return bd
end

# ‚ïî‚ïê‚ï° 234d7462-e4bd-4a7c-9ed4-7160a6a9ffb9
"""
Compute KL divergence between `Q(c|x_i)` and `Q(c|x)` for each i.
Here `Q(c|x)` is the accumulated coherent information across all the instances, and 
`Q(c|x_i)` is the posterior for the ith instance.
"""
function kl_Qc_accumulated(symae_para, model, D, n, doptim, kopt, alpha=0.0)
    # coherent_codes_all = model(D, Val(:coherent))
    coherent_code_all = model(doptim, Val(:coherent))
    coherent_code_all_batched = batch_coherent_codes(coherent_code_all, kopt)
    kls = map(D) do d
        optimal_nuisance_model = get_Model_Optimal_Nuisance(symae_para, model, init=d)

        _, B = loss_kl_Qc_accumulated(
            optimal_nuisance_model,
            coherent_code_all_batched,
            alpha,
        )
        return B
    end
    I = vcat(map(enumerate(D)) do (i, d)
        fill(i, size(d, 2))
    end...)
    J = vcat(map(D) do d
        collect(1:size(d, 2))
    end...)
    perm = sortperm(vcat(kls...))
    return kls, I[perm[1:n]], J[perm[1:n]]
end

# ‚ïî‚ïê‚ï° 7931ce6a-a062-4c7f-bb04-82b822e04eab
md"""
## Training
- ntau: number of waveforms used per step (as large as your GPU memory supports)
- beta: custom weight of the KL terms in this order [[nuisance], [coherent, lambda]]
- batchsize: because of stochastic gradient descent
- nsteps: how long you want a single epoch to be?
- gamma: 
- tau:
- nepoch:
- nprint:
- initial_learning_rate:
"""

# ‚ïî‚ïê‚ï° eafe181e-19e9-409e-ad1d-ce859cf0e672
Base.@kwdef struct Training_Para
    ntau::Int = 20
    beta = (; N=[1f0], C=[1f0, 1f0])
    gamma::Float32 = 1f2
    temperature::Float32 = 1f0
    batchsize::Int = 32
    nsteps::Int = 100
    nprint::Int = 1
    nepoch::Int = 10
    initial_learning_rate::Float64 = 0.001
end

# ‚ïî‚ïê‚ï° 7f8094da-d6a6-4b3d-b16c-cb0d7e928b9d
"""
train SymAE model using `get_data_iterator`
"""
function update(model, loss_history, data_train, data_test, training_para=SymAE_Training_Para())
    lr_s = Exp(start=training_para.initial_learning_rate, decay=0.99)
    opt_state = Optimisers.setup(Optimisers.AdamW(eta=training_para.initial_learning_rate), model)
    ntau = min(training_para.ntau, minimum(getindex.(size.(data_train), 2)))
    ntau_test = min(training_para.ntau, minimum(getindex.(size.(data_test), 2)))
    # dup_model = Enzyme.Duplicated(model)
    @progress name = "training" for epoch = 1:training_para.nepoch

        Xtrain = get_data_iterator(
            data_train;
            ntau=ntau,
            batchsize=training_para.batchsize,
            nsteps=training_para.nsteps,
        )
        Xtest = get_data_iterator(
            data_test,
            ntau=ntau_test,
            batchsize=training_para.batchsize,
            nsteps=training_para.nsteps,
        )

        # compute losses per epoch for a sample
        xtrain = first(Xtrain)
        xtest = first(Xtest)
        push!(loss_history.train_mse, loss_mse(model, xtrain))
        push!(loss_history.test_mse, loss_mse(model, xtest))
        train_loss = loss_sym_vae(model, xtrain, training_para.beta, training_para.gamma, training_para.temperature)
        test_loss = loss_sym_vae(model, xtest, training_para.beta, training_para.gamma, training_para.temperature)
        push!(loss_history.train_neg_llh, train_loss.neg_llh)
        push!(loss_history.test_neg_llh, test_loss.neg_llh)
        push!(loss_history.train_kl, train_loss.kl)
        push!(loss_history.test_kl, test_loss.kl)
        push!(loss_history.train_neg_elbo, train_loss.neg_elbo)
        push!(loss_history.test_neg_elbo, test_loss.neg_elbo)

        # learning rate depending on how many epochs we have already run
        Optimisers.adjust!(opt_state, lr_s(epoch))

        loss(model, data) = loss_sym_vae(model, data, training_para.beta, training_para.gamma, training_para.temperature).neg_elbo

        for x in Xtrain
            # g = Flux.gradient(loss, dup_model, Const(x))[1]
            g = Flux.gradient(loss, model, x)[1]
            Optimisers.update!(opt_state, model, g)
        end


        # print output every 10 epochs
        if (mod(epoch, training_para.nprint) == 0)
            @info merge((; epoch=epoch), map(last, loss_history))
        end
    end
    return nothing
end

# ‚ïî‚ïê‚ï° 7e3a8840-ed33-4d7c-a3b0-f6f458e2a72d
"""
alternate training between (encoder, decoder) and (transformer) of SymAE
"""
function update_alternating_transformer(model, loss_history, data_train, data_test, training_para=SymAE_Training_Para())
    lr_s = Exp(start=training_para.initial_learning_rate, decay=0.99)
    opt_state = Optimisers.setup(Optimisers.AdamW(eta=training_para.initial_learning_rate), model)
    loss(model, data) = loss_sym_vae(model, data, training_para.beta, training_para.gamma, training_para.temperature).neg_elbo
    ntau = min(training_para.ntau, minimum(getindex.(size.(data_train), 2)))
    ntau_test = min(training_para.ntau, minimum(getindex.(size.(data_test), 2)))
    # dup_model = Enzyme.Duplicated(model)
    @progress name = "training" for epoch = 1:training_para.nepoch
        Xtrain = get_data_iterator(
            data_train;
            ntau=ntau,
            batchsize=training_para.batchsize,
            nsteps=training_para.nsteps,
        )
        Xtest = get_data_iterator(
            data_test,
            ntau=ntau_test,
            batchsize=training_para.batchsize,
            nsteps=training_para.nsteps,
        )

        # compute losses per epoch for a sample
        xtrain = first(Xtrain)
        xtest = first(Xtest)
        push!(loss_history.train_mse, loss_mse(model, xtrain))
        push!(loss_history.test_mse, loss_mse(model, xtest))
        train_loss = loss_sym_vae(model, xtrain, training_para.beta, training_para.gamma, training_para.temperature)
        test_loss = loss_sym_vae(model, xtest, training_para.beta, training_para.gamma, training_para.temperature)
        push!(loss_history.train_neg_llh, train_loss.neg_llh)
        push!(loss_history.test_neg_llh, test_loss.neg_llh)
        push!(loss_history.train_kl, train_loss.kl)
        push!(loss_history.test_kl, test_loss.kl)
        push!(loss_history.train_neg_elbo, train_loss.neg_elbo)
        push!(loss_history.test_neg_elbo, test_loss.neg_elbo)


        # learning rate depending on how many epochs (from loss_history) we have already run
        Optimisers.adjust!(opt_state, lr_s(epoch))


        N = 2 # N epochs before alternating
        # only update encoder and decoders
        Optimisers.freeze!(opt_state.transformerb)
        for i in 1:N
            for x in Xtrain
                # g = Flux.gradient(loss, dup_model, Const(x))[1]
                g = Flux.gradient(loss, model, x)[1]
                Optimisers.update!(opt_state, model, g)
            end
        end
        Optimisers.thaw!(opt_state.transformerb)


        # only update transformer parameter
        Optimisers.freeze!(opt_state.sencb)
        Optimisers.freeze!(opt_state.nencb)
        Optimisers.freeze!(opt_state.decb)
        for i in 1:N
            for x in Xtrain
                # g = Flux.gradient(loss, dup_model, Const(x))[1]
                g = Flux.gradient(loss, model, x)[1]
                Optimisers.update!(opt_state, model, g)
            end
        end
        Optimisers.thaw!(opt_state.sencb)
        Optimisers.thaw!(opt_state.nencb)
        Optimisers.thaw!(opt_state.decb)



        # print output every 10 epochs
        if (mod(epoch, training_para.nprint) == 0)
            @info merge((; epoch=epoch), map(last, loss_history))
        end
    end
    return nothing
end

# ‚ïî‚ïê‚ï° 0541d3c6-24cf-46b1-95a1-39f3341aec4f
"""
alternate training between (encoder, decoder) and (transformer) of SymAE
"""
function update_alternating_transformer_batchviews(model, loss_history, data_train, data_test, training_para=SymAE_Training_Para())
    lr_s = Exp(start=training_para.initial_learning_rate, decay=0.99)
    opt_state = Optimisers.setup(Optimisers.AdamW(eta=training_para.initial_learning_rate), model)
    loss(model, data) = loss_sym_vae(model, data, training_para.beta, training_para.gamma, training_para.temperature).neg_elbo
    ntau = min(training_para.ntau, minimum(getindex.(size.(data_train), 2)))
    ntau_test = min(training_para.ntau, minimum(getindex.(size.(data_test), 2)))
    # dup_model = Enzyme.Duplicated(model)
    @progress name = "training" for epoch = 1:training_para.nepoch
        Xtrain = get_batchviews(data_train, ntau)
        Xtest = get_batchviews(data_test, ntau_test)

        # compute losses per epoch for a sample
        xtrain = get_sample(Xtrain, training_para.batchsize)
        xtest = get_sample(Xtest, training_para.batchsize)
        push!(loss_history.train_mse, loss_mse(model, xtrain))
        push!(loss_history.test_mse, loss_mse(model, xtest))
        train_loss = loss_sym_vae(model, xtrain, training_para.beta, training_para.gamma, training_para.temperature)
        test_loss = loss_sym_vae(model, xtest, training_para.beta, training_para.gamma, training_para.temperature)
        push!(loss_history.train_neg_llh, train_loss.neg_llh)
        push!(loss_history.test_neg_llh, test_loss.neg_llh)
        push!(loss_history.train_kl, train_loss.kl)
        push!(loss_history.test_kl, test_loss.kl)
        push!(loss_history.train_neg_elbo, train_loss.neg_elbo)
        push!(loss_history.test_neg_elbo, test_loss.neg_elbo)


        # learning rate depending on how many epochs (from loss_history) we have already run
        Optimisers.adjust!(opt_state, lr_s(epoch))


        N = 2 # N epochs before alternating
        # only update encoder and decoders
        Optimisers.freeze!(opt_state.transformerb)
        for i in 1:N
            for i = 1:training_para.nsteps
                x = get_sample(Xtrain, training_para.batchsize)
                # g = Flux.gradient(loss, dup_model, Const(x))[1]
                g = Flux.gradient(loss, model, x)[1]
                Optimisers.update!(opt_state, model, g)
            end
        end
        Optimisers.thaw!(opt_state.transformerb)


        # only update transformer parameter
        Optimisers.freeze!(opt_state.sencb)
        Optimisers.freeze!(opt_state.nencb)
        Optimisers.freeze!(opt_state.decb)
        for i in 1:N
            for i = 1:training_para.nsteps
                x = get_sample(Xtrain, training_para.batchsize)
                # g = Flux.gradient(loss, dup_model, Const(x))[1]
                g = Flux.gradient(loss, model, x)[1]
                Optimisers.update!(opt_state, model, g)
            end
        end
        Optimisers.thaw!(opt_state.sencb)
        Optimisers.thaw!(opt_state.nencb)
        Optimisers.thaw!(opt_state.decb)



        # print output every 10 epochs
        if (mod(epoch, training_para.nprint) == 0)
            @info merge((; epoch=epoch), map(last, loss_history))
        end
    end
    return nothing
end

# ‚ïî‚ïê‚ï° 483e596b-afbc-45d5-84d4-847959c5b6ea
"""
train SymAE model using `get_batchviews`
"""
function update_with_batchviews(model, loss_history, data_train, data_test, para, training_para=SymAE_Training_Para())
    opt_state = Optimisers.setup(Optimisers.AdamW(para.learning_rate), model)
    loss(model, data) = loss_sym_vae(model, data, training_para.beta).neg_elbo
    ntau = min(training_para.ntau, minimum(getindex.(size.(data_train), 2)))
    ntau_test = min(training_para.ntau, minimum(getindex.(size.(data_test), 2)))

    @progress name = "training" for epoch = 1:training_para.nepoch
        Xtrain = get_batchviews(data_train, ntau)
        Xtest = get_batchviews(data_test, ntau_test)

        # compute losses per epoch for a sample
        xtrain = get_sample(Xtrain, para.batchsize)
        xtest = get_sample(Xtest, para.batchsize)
        push!(loss_history.train_mse, loss_mse(model, xtrain))
        push!(loss_history.test_mse, loss_mse(model, xtest))
        train_loss = loss_sym_vae(model, xtrain, training_para.beta, training_para.gamma, training_para.temperature)
        test_loss = loss_sym_vae(model, xtest, training_para.beta, training_para.gamma, training_para.temperature)
        push!(loss_history.train_neg_llh, train_loss.neg_llh)
        push!(loss_history.test_neg_llh, test_loss.neg_llh)
        push!(loss_history.train_kl, train_loss.kl)
        push!(loss_history.test_kl, test_loss.kl)
        push!(loss_history.train_neg_elbo, train_loss.neg_elbo)
        push!(loss_history.test_neg_elbo, test_loss.neg_elbo)

        for i = 1:para.nsteps # number of steps per epoch
            x = get_sample(Xtrain, para.batchsize)
            g = Flux.gradient(loss, model, x)[1]
            Optimisers.update!(opt_state, model, g)
        end

        # print output every 10 epochs
        if (mod(epoch, training_para.nprint) == 0)
            @info merge((; epoch=epoch), map(last, loss_history))
        end
    end
    return nothing
end

# ‚ïî‚ïê‚ï° 61fbbf84-1b2b-4de9-8763-800f76c851e0
md"## Redatuming"

# ‚ïî‚ïê‚ï° 0f0fe0e8-a239-474b-b9af-54507cb968aa
"""
use virtual data where source is used from x and nuisance from xaug
"""
function generate_virtual_data(x, xaug, nnoise, cnoise, model)
    output = model(x, xaug, nnoise, cnoise)
    return output.X.xhat
end

# ‚ïî‚ïê‚ï° 7531c2eb-5505-4ad2-9f79-111bed3bef74
"""
    redatum(d1, d2, model, nnoise=false, cnoise=false)

Redatum two input data `d1` and `d2` using the given `model`. The `model` should be a function that takes input data and returns the redatumed output.

## Arguments
- `d1`: The first input data.
- `d2`: The second input data.
- `model`: symae model
- `nnoise`: A boolean indicating whether to sample Q(n|x) or use its mean
- `cnoise`: A boolean indicating whether to sample Q(c|x) or use its mean

## Returns
A named tuple containing the redatumed data `d1hat`, `d2hat`, `d12hat`, and `d21hat`.
"""
function redatum(d1, d2, model, nnoise=false, cnoise=false)
    d1hat = model(d1, nnoise, cnoise).X.xhat
    d2hat = model(d2, nnoise, cnoise).X.xhat
    d12hat = model(d1, d2, nnoise, cnoise).X.xhat
    d21hat = model(d2, d1, nnoise, cnoise).X.xhat
    return map(cpu, (; d1=d1, d2=d2, d1hat, d2hat, d12hat, d21hat))
end

# ‚ïî‚ïê‚ï° 5d25db74-dcc2-49d6-b62a-39f612089e9f
md"## Plots"

# ‚ïî‚ïê‚ï° c9f4b3e6-6691-4e7f-86c7-dcacdde924a5
function plot_loss_history(loss_history; title="")
    trace = [
        PlutoPlotly.scatter(
            y=getfield(loss_history, label),
            mode="lines",
            name=label,
        ) for label in [:train_mse, :test_mse]
    ]

    trace2 = [
        PlutoPlotly.scatter(
            y=getfield(loss_history, label),
            mode="lines",
            name=label,
        ) for label in [
            :train_neg_llh,
            :test_neg_llh,
            :train_kl,
            :test_kl,
            :train_neg_elbo,
            :test_neg_elbo,
        ]
    ]

    layout = Layout(
        title=title,
        yaxis=attr(gridwidth=1),
        xaxis=attr(title="Epochs"),
        yaxis_type="log",
    )

    layout2 = Layout(
        title="",
        yaxis=attr(gridwidth=1),
        xaxis=attr(title="Epochs"),
        yaxis_type="",
    )

    p1 = PlutoPlotly.plot(trace, layout)
    p2 = PlutoPlotly.plot(trace2, layout2)
    p = [p1 p2]
    relayout!(p, height=250, width=700, title_text="SymAE Loss History")
    p
    # PlutoPlotly.plot([trace trace], layout)
end

# ‚ïî‚ïê‚ï° 0a2fb24a-3c7a-46ed-ad54-d35fb72f8031
md"## Misc"

# ‚ïî‚ïê‚ï° 1a8619c6-4c19-4f55-a968-d18a4f1016e7
function taper(x)
    w = xpu(cat(tukey(size(x, 1), 0.1), dims=ndims(x)))
    return w .* x
end

# ‚ïî‚ïê‚ï° 63f7880d-9353-4857-b751-36b6f5f45d68
md"""
# JUNK
"""

# ‚ïî‚ïê‚ï° 00000000-0000-0000-0000-000000000001
PLUTO_PROJECT_TOML_CONTENTS = """
[deps]
BlackBoxOptim = "a134a8b2-14d6-55f6-9291-3336d3ab0209"
CUDA = "052768ef-5323-5732-b1bb-66c8b64840ba"
DSP = "717857b8-e6f2-59f4-9121-6e50c889abd2"
Enzyme = "7da242da-08ed-463a-9acd-ee780be4f1d9"
FFTW = "7a1cc6ca-52ef-59f5-83cd-3a7055c09341"
Flux = "587475ba-b771-5e3f-ad9e-33799f191a9c"
LinearAlgebra = "37e2e46d-f89d-539d-b4ee-838fcccc9c8e"
MLUtils = "f1d291b0-491e-4a28-83b9-f70985020b54"
Metaheuristics = "bcdb8e00-2c21-11e9-3065-2b553b22f898"
Metalhead = "dbeba491-748d-5e0e-a39e-b530a07fa0cc"
Optimisers = "3bd65402-5787-11e9-1adc-39752487f4e2"
ParameterSchedulers = "d7d3b36b-41b8-4d0d-a2bf-768c6151755e"
PlutoPlotly = "8e989ff0-3d88-8e9f-f020-2b208a939ff0"
PlutoUI = "7f904dfe-b85e-4ff6-b463-dae2292396a8"
ProgressLogging = "33c8b6b6-d38a-422a-b730-caa89a2f386c"
Random = "9a3f8284-a2c9-5f02-9a11-845980a1fd5c"
Statistics = "10745b16-79ce-11e8-11f9-7d13ad32a3b2"
cuDNN = "02a925ec-e4fe-4b08-9a7e-0d78e3d38ccd"

[compat]
BlackBoxOptim = "~0.6.3"
CUDA = "~5.8.2"
DSP = "~0.8.4"
Enzyme = "~0.13.23"
FFTW = "~1.9.0"
Flux = "~0.16.4"
MLUtils = "~0.4.8"
Metaheuristics = "~3.4.0"
Metalhead = "~0.9.5"
Optimisers = "~0.4.6"
ParameterSchedulers = "~0.4.3"
PlutoPlotly = "~0.6.3"
PlutoUI = "~0.7.66"
ProgressLogging = "~0.1.5"
cuDNN = "~1.4.3"
"""

# ‚ïî‚ïê‚ï° 00000000-0000-0000-0000-000000000002
PLUTO_MANIFEST_TOML_CONTENTS = """
# This file is machine-generated - editing it directly is not advised

julia_version = "1.11.3"
manifest_format = "2.0"
project_hash = "03ec92b705a2ef4e4101ea0fa524bcb1d11eaadb"

[[deps.AbstractFFTs]]
deps = ["LinearAlgebra"]
git-tree-sha1 = "d92ad398961a3ed262d8bf04a1a2b8340f915fef"
uuid = "621f4979-c628-5d54-868e-fcf4e3e8185c"
version = "1.5.0"
weakdeps = ["ChainRulesCore", "Test"]

    [deps.AbstractFFTs.extensions]
    AbstractFFTsChainRulesCoreExt = "ChainRulesCore"
    AbstractFFTsTestExt = "Test"

[[deps.AbstractPlutoDingetjes]]
deps = ["Pkg"]
git-tree-sha1 = "6e1d2a35f2f90a4bc7c2ed98079b2ba09c35b83a"
uuid = "6e696c72-6542-2067-7265-42206c756150"
version = "1.3.2"

[[deps.Accessors]]
deps = ["CompositionsBase", "ConstructionBase", "Dates", "InverseFunctions", "MacroTools"]
git-tree-sha1 = "3b86719127f50670efe356bc11073d84b4ed7a5d"
uuid = "7d9f7c33-5ae7-4f3b-8dc6-eff91059b697"
version = "0.1.42"

    [deps.Accessors.extensions]
    AxisKeysExt = "AxisKeys"
    IntervalSetsExt = "IntervalSets"
    LinearAlgebraExt = "LinearAlgebra"
    StaticArraysExt = "StaticArrays"
    StructArraysExt = "StructArrays"
    TestExt = "Test"
    UnitfulExt = "Unitful"

    [deps.Accessors.weakdeps]
    AxisKeys = "94b1ba4f-4ee9-5380-92f1-94cde586c3c5"
    IntervalSets = "8197267c-284f-5f27-9208-e0e47529a953"
    LinearAlgebra = "37e2e46d-f89d-539d-b4ee-838fcccc9c8e"
    StaticArrays = "90137ffa-7385-5640-81b9-e52037218182"
    StructArrays = "09ab397b-f2b6-538f-b94a-2f83cf4a842a"
    Test = "8dfed614-e22c-5e08-85e1-65c5234f0b40"
    Unitful = "1986cc42-f94f-5a68-af5c-568840ba703d"

[[deps.Adapt]]
deps = ["LinearAlgebra", "Requires"]
git-tree-sha1 = "f7817e2e585aa6d924fd714df1e2a84be7896c60"
uuid = "79e6a3ab-5dfb-504d-930d-738a2a938a0e"
version = "4.3.0"
weakdeps = ["SparseArrays", "StaticArrays"]

    [deps.Adapt.extensions]
    AdaptSparseArraysExt = "SparseArrays"
    AdaptStaticArraysExt = "StaticArrays"

[[deps.AliasTables]]
deps = ["PtrArrays", "Random"]
git-tree-sha1 = "9876e1e164b144ca45e9e3198d0b689cadfed9ff"
uuid = "66dad0bd-aa9a-41b7-9441-69ab47430ed8"
version = "1.1.3"

[[deps.ArgCheck]]
git-tree-sha1 = "f9e9a66c9b7be1ad7372bbd9b062d9230c30c5ce"
uuid = "dce04be8-c92d-5529-be00-80e4d2c0e197"
version = "2.5.0"

[[deps.ArgTools]]
uuid = "0dad84c5-d112-42e6-8d28-ef12dabb789f"
version = "1.1.2"

[[deps.ArrayLayouts]]
deps = ["FillArrays", "LinearAlgebra"]
git-tree-sha1 = "4e25216b8fea1908a0ce0f5d87368587899f75be"
uuid = "4c555306-a7a7-4459-81d9-ec55ddd5c99a"
version = "1.11.1"
weakdeps = ["SparseArrays"]

    [deps.ArrayLayouts.extensions]
    ArrayLayoutsSparseArraysExt = "SparseArrays"

[[deps.Artifacts]]
uuid = "56f22d72-fd6d-98f1-02f0-08ddc0907c33"
version = "1.11.0"

[[deps.Atomix]]
deps = ["UnsafeAtomics"]
git-tree-sha1 = "b5bb4dc6248fde467be2a863eb8452993e74d402"
uuid = "a9b6321e-bd34-4604-b9c9-b65b8de01458"
version = "1.1.1"

    [deps.Atomix.extensions]
    AtomixCUDAExt = "CUDA"
    AtomixMetalExt = "Metal"
    AtomixOpenCLExt = "OpenCL"
    AtomixoneAPIExt = "oneAPI"

    [deps.Atomix.weakdeps]
    CUDA = "052768ef-5323-5732-b1bb-66c8b64840ba"
    Metal = "dde4c033-4e86-420c-a63e-0dd931031962"
    OpenCL = "08131aa3-fb12-5dee-8b74-c09406e224a2"
    oneAPI = "8f75cd03-7ff8-4ecb-9b8f-daf728133b1b"

[[deps.BFloat16s]]
deps = ["LinearAlgebra", "Printf", "Random"]
git-tree-sha1 = "3b642331600250f592719140c60cf12372b82d66"
uuid = "ab4f0b2a-ad5b-11e8-123f-65d77653426b"
version = "0.5.1"

[[deps.BSON]]
git-tree-sha1 = "4c3e506685c527ac6a54ccc0c8c76fd6f91b42fb"
uuid = "fbb218c0-5317-5bc6-957e-2ee96dd4b1f0"
version = "0.3.9"

[[deps.BangBang]]
deps = ["Accessors", "ConstructionBase", "InitialValues", "LinearAlgebra"]
git-tree-sha1 = "26f41e1df02c330c4fa1e98d4aa2168fdafc9b1f"
uuid = "198e06fe-97b7-11e9-32a5-e1d131e6ad66"
version = "0.4.4"

    [deps.BangBang.extensions]
    BangBangChainRulesCoreExt = "ChainRulesCore"
    BangBangDataFramesExt = "DataFrames"
    BangBangStaticArraysExt = "StaticArrays"
    BangBangStructArraysExt = "StructArrays"
    BangBangTablesExt = "Tables"
    BangBangTypedTablesExt = "TypedTables"

    [deps.BangBang.weakdeps]
    ChainRulesCore = "d360d2e6-b24c-11e9-a2a3-2a2ae2dbcce4"
    DataFrames = "a93c6f00-e57d-5684-b7b6-d8193f3e46c0"
    StaticArrays = "90137ffa-7385-5640-81b9-e52037218182"
    StructArrays = "09ab397b-f2b6-538f-b94a-2f83cf4a842a"
    Tables = "bd369af6-aec1-5ad0-b16a-f7cc5008161c"
    TypedTables = "9d95f2ec-7b3d-5a63-8d20-e2491e220bb9"

[[deps.Base64]]
uuid = "2a0f44e3-6c83-55bd-87e4-b1978d98bd5f"
version = "1.11.0"

[[deps.Baselet]]
git-tree-sha1 = "aebf55e6d7795e02ca500a689d326ac979aaf89e"
uuid = "9718e550-a3fa-408a-8086-8db961cd8217"
version = "0.1.1"

[[deps.Bessels]]
git-tree-sha1 = "4435559dc39793d53a9e3d278e185e920b4619ef"
uuid = "0e736298-9ec6-45e8-9647-e4fc86a2fe38"
version = "0.2.8"

[[deps.BlackBoxOptim]]
deps = ["CPUTime", "Compat", "Distributed", "Distributions", "JSON", "LinearAlgebra", "Printf", "Random", "Requires", "SpatialIndexing", "StatsBase"]
git-tree-sha1 = "9c203a2515b5eeab8f2987614d2b1db83ef03542"
uuid = "a134a8b2-14d6-55f6-9291-3336d3ab0209"
version = "0.6.3"

    [deps.BlackBoxOptim.extensions]
    BlackBoxOptimRealtimePlotServerExt = ["HTTP", "Sockets"]

    [deps.BlackBoxOptim.weakdeps]
    HTTP = "cd3eb016-35fb-5094-929b-558a96fad6f3"
    Sockets = "6462fe0b-24de-5631-8697-dd941f90decc"

[[deps.CEnum]]
git-tree-sha1 = "389ad5c84de1ae7cf0e28e381131c98ea87d54fc"
uuid = "fa961155-64e5-5f13-b03f-caf6b980ea82"
version = "0.5.0"

[[deps.CPUTime]]
git-tree-sha1 = "2dcc50ea6a0a1ef6440d6eecd0fe3813e5671f45"
uuid = "a9c8d775-2e2e-55fc-8582-045d282d599e"
version = "1.0.0"

[[deps.CUDA]]
deps = ["AbstractFFTs", "Adapt", "BFloat16s", "CEnum", "CUDA_Driver_jll", "CUDA_Runtime_Discovery", "CUDA_Runtime_jll", "Crayons", "DataFrames", "ExprTools", "GPUArrays", "GPUCompiler", "GPUToolbox", "KernelAbstractions", "LLVM", "LLVMLoopInfo", "LazyArtifacts", "Libdl", "LinearAlgebra", "Logging", "NVTX", "Preferences", "PrettyTables", "Printf", "Random", "Random123", "RandomNumbers", "Reexport", "Requires", "SparseArrays", "StaticArrays", "Statistics", "demumble_jll"]
git-tree-sha1 = "b8ae59258f3d96ce75a00f9229e719356eb929d6"
uuid = "052768ef-5323-5732-b1bb-66c8b64840ba"
version = "5.8.2"

    [deps.CUDA.extensions]
    ChainRulesCoreExt = "ChainRulesCore"
    EnzymeCoreExt = "EnzymeCore"
    SparseMatricesCSRExt = "SparseMatricesCSR"
    SpecialFunctionsExt = "SpecialFunctions"

    [deps.CUDA.weakdeps]
    ChainRulesCore = "d360d2e6-b24c-11e9-a2a3-2a2ae2dbcce4"
    EnzymeCore = "f151be2c-9106-41f4-ab19-57ee4f262869"
    SparseMatricesCSR = "a0a7dd2c-ebf4-11e9-1f05-cf50bc540ca1"
    SpecialFunctions = "276daf66-3868-5448-9aa4-cd146d93841b"

[[deps.CUDA_Driver_jll]]
deps = ["Artifacts", "JLLWrappers", "Libdl", "Pkg"]
git-tree-sha1 = "18afa851ed10552e6df25dfaa7ef450104ae73d4"
uuid = "4ee394cb-3365-5eb0-8335-949819d2adfc"
version = "0.13.1+0"

[[deps.CUDA_Runtime_Discovery]]
deps = ["Libdl"]
git-tree-sha1 = "33576c7c1b2500f8e7e6baa082e04563203b3a45"
uuid = "1af6417a-86b4-443c-805f-a4643ffb695f"
version = "0.3.5"

[[deps.CUDA_Runtime_jll]]
deps = ["Artifacts", "CUDA_Driver_jll", "JLLWrappers", "LazyArtifacts", "Libdl", "TOML"]
git-tree-sha1 = "b5c173a64f9f4224a82fdc26fda8614cb2ecfa27"
uuid = "76a88914-d11a-5bdc-97e0-2f5a05c973a2"
version = "0.17.1+0"

[[deps.CUDNN_jll]]
deps = ["Artifacts", "CUDA_Runtime_jll", "JLLWrappers", "LazyArtifacts", "Libdl", "TOML"]
git-tree-sha1 = "12ab2a3e7d1e5f523e95b94cd9334ebcf5be220e"
uuid = "62b44479-cb7b-5706-934f-f13b2eb2e645"
version = "9.10.0+0"

[[deps.ChainRules]]
deps = ["Adapt", "ChainRulesCore", "Compat", "Distributed", "GPUArraysCore", "IrrationalConstants", "LinearAlgebra", "Random", "RealDot", "SparseArrays", "SparseInverseSubset", "Statistics", "StructArrays", "SuiteSparse"]
git-tree-sha1 = "224f9dc510986549c8139def08e06f78c562514d"
uuid = "082447d4-558c-5d27-93f4-14fc19e9eca2"
version = "1.72.5"

[[deps.ChainRulesCore]]
deps = ["Compat", "LinearAlgebra"]
git-tree-sha1 = "06ee8d1aa558d2833aa799f6f0b31b30cada405f"
uuid = "d360d2e6-b24c-11e9-a2a3-2a2ae2dbcce4"
version = "1.25.2"
weakdeps = ["SparseArrays"]

    [deps.ChainRulesCore.extensions]
    ChainRulesCoreSparseArraysExt = "SparseArrays"

[[deps.ColorSchemes]]
deps = ["ColorTypes", "ColorVectorSpace", "Colors", "FixedPointNumbers", "PrecompileTools", "Random"]
git-tree-sha1 = "403f2d8e209681fcbd9468a8514efff3ea08452e"
uuid = "35d6a980-a343-548e-a6ea-1d62b119f2f4"
version = "3.29.0"

[[deps.ColorTypes]]
deps = ["FixedPointNumbers", "Random"]
git-tree-sha1 = "b10d0b65641d57b8b4d5e234446582de5047050d"
uuid = "3da002f7-5984-5a60-b8a6-cbb66c0b333f"
version = "0.11.5"

[[deps.ColorVectorSpace]]
deps = ["ColorTypes", "FixedPointNumbers", "LinearAlgebra", "Requires", "Statistics", "TensorCore"]
git-tree-sha1 = "a1f44953f2382ebb937d60dafbe2deea4bd23249"
uuid = "c3611d14-8923-5661-9e6a-0046d554d3a4"
version = "0.10.0"
weakdeps = ["SpecialFunctions"]

    [deps.ColorVectorSpace.extensions]
    SpecialFunctionsExt = "SpecialFunctions"

[[deps.Colors]]
deps = ["ColorTypes", "FixedPointNumbers", "Reexport"]
git-tree-sha1 = "362a287c3aa50601b0bc359053d5c2468f0e7ce0"
uuid = "5ae59095-9a9b-59fe-a467-6f913c188581"
version = "0.12.11"

[[deps.Combinatorics]]
git-tree-sha1 = "8010b6bb3388abe68d95743dcbea77650bb2eddf"
uuid = "861a8166-3701-5b0c-9a16-15d98fcdc6aa"
version = "1.0.3"

[[deps.CommonSubexpressions]]
deps = ["MacroTools"]
git-tree-sha1 = "cda2cfaebb4be89c9084adaca7dd7333369715c5"
uuid = "bbf7d656-a473-5ed7-a52c-81e309532950"
version = "0.3.1"

[[deps.Compat]]
deps = ["TOML", "UUIDs"]
git-tree-sha1 = "3a3dfb30697e96a440e4149c8c51bf32f818c0f3"
uuid = "34da2185-b29b-5c13-b0c7-acf172513d20"
version = "4.17.0"
weakdeps = ["Dates", "LinearAlgebra"]

    [deps.Compat.extensions]
    CompatLinearAlgebraExt = "LinearAlgebra"

[[deps.CompilerSupportLibraries_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "e66e0078-7015-5450-92f7-15fbd957f2ae"
version = "1.1.1+0"

[[deps.CompositionsBase]]
git-tree-sha1 = "802bb88cd69dfd1509f6670416bd4434015693ad"
uuid = "a33af91c-f02d-484b-be07-31d278c5ca2b"
version = "0.1.2"
weakdeps = ["InverseFunctions"]

    [deps.CompositionsBase.extensions]
    CompositionsBaseInverseFunctionsExt = "InverseFunctions"

[[deps.ConstructionBase]]
git-tree-sha1 = "b4b092499347b18a015186eae3042f72267106cb"
uuid = "187b0558-2788-49d3-abe0-74a17ed4e7c9"
version = "1.6.0"

    [deps.ConstructionBase.extensions]
    ConstructionBaseIntervalSetsExt = "IntervalSets"
    ConstructionBaseLinearAlgebraExt = "LinearAlgebra"
    ConstructionBaseStaticArraysExt = "StaticArrays"

    [deps.ConstructionBase.weakdeps]
    IntervalSets = "8197267c-284f-5f27-9208-e0e47529a953"
    LinearAlgebra = "37e2e46d-f89d-539d-b4ee-838fcccc9c8e"
    StaticArrays = "90137ffa-7385-5640-81b9-e52037218182"

[[deps.ContextVariablesX]]
deps = ["Compat", "Logging", "UUIDs"]
git-tree-sha1 = "25cc3803f1030ab855e383129dcd3dc294e322cc"
uuid = "6add18c4-b38d-439d-96f6-d6bc489c04c5"
version = "0.1.3"

[[deps.Crayons]]
git-tree-sha1 = "249fe38abf76d48563e2f4556bebd215aa317e15"
uuid = "a8cc5b0e-0ffa-5ad4-8c14-923d3ee1735f"
version = "4.1.1"

[[deps.DSP]]
deps = ["Bessels", "FFTW", "IterTools", "LinearAlgebra", "Polynomials", "Random", "Reexport", "SpecialFunctions", "Statistics"]
git-tree-sha1 = "5989debfc3b38f736e69724818210c67ffee4352"
uuid = "717857b8-e6f2-59f4-9121-6e50c889abd2"
version = "0.8.4"

    [deps.DSP.extensions]
    OffsetArraysExt = "OffsetArrays"

    [deps.DSP.weakdeps]
    OffsetArrays = "6fe1bfb0-de20-5000-8ca7-80f57d26f881"

[[deps.DataAPI]]
git-tree-sha1 = "abe83f3a2f1b857aac70ef8b269080af17764bbe"
uuid = "9a962f9c-6df0-11e9-0e5d-c546b8b5ee8a"
version = "1.16.0"

[[deps.DataFrames]]
deps = ["Compat", "DataAPI", "DataStructures", "Future", "InlineStrings", "InvertedIndices", "IteratorInterfaceExtensions", "LinearAlgebra", "Markdown", "Missings", "PooledArrays", "PrecompileTools", "PrettyTables", "Printf", "Random", "Reexport", "SentinelArrays", "SortingAlgorithms", "Statistics", "TableTraits", "Tables", "Unicode"]
git-tree-sha1 = "fb61b4812c49343d7ef0b533ba982c46021938a6"
uuid = "a93c6f00-e57d-5684-b7b6-d8193f3e46c0"
version = "1.7.0"

[[deps.DataStructures]]
deps = ["Compat", "InteractiveUtils", "OrderedCollections"]
git-tree-sha1 = "4e1fe97fdaed23e9dc21d4d664bea76b65fc50a0"
uuid = "864edb3b-99cc-5e75-8d2d-829cb0a9cfe8"
version = "0.18.22"

[[deps.DataValueInterfaces]]
git-tree-sha1 = "bfc1187b79289637fa0ef6d4436ebdfe6905cbd6"
uuid = "e2d170a0-9d28-54be-80f0-106bbe20a464"
version = "1.0.0"

[[deps.Dates]]
deps = ["Printf"]
uuid = "ade2ca70-3891-5945-98fb-dc099432e06a"
version = "1.11.0"

[[deps.DefineSingletons]]
git-tree-sha1 = "0fba8b706d0178b4dc7fd44a96a92382c9065c2c"
uuid = "244e2a9f-e319-4986-a169-4d1fe445cd52"
version = "0.1.2"

[[deps.DelimitedFiles]]
deps = ["Mmap"]
git-tree-sha1 = "9e2f36d3c96a820c678f2f1f1782582fcf685bae"
uuid = "8bb1440f-4735-579b-a4ab-409b98df4dab"
version = "1.9.1"

[[deps.DiffResults]]
deps = ["StaticArraysCore"]
git-tree-sha1 = "782dd5f4561f5d267313f23853baaaa4c52ea621"
uuid = "163ba53b-c6d8-5494-b064-1a9d43ac40c5"
version = "1.1.0"

[[deps.DiffRules]]
deps = ["IrrationalConstants", "LogExpFunctions", "NaNMath", "Random", "SpecialFunctions"]
git-tree-sha1 = "23163d55f885173722d1e4cf0f6110cdbaf7e272"
uuid = "b552c78f-8df3-52c6-915a-8e097449b14b"
version = "1.15.1"

[[deps.Distances]]
deps = ["LinearAlgebra", "Statistics", "StatsAPI"]
git-tree-sha1 = "c7e3a542b999843086e2f29dac96a618c105be1d"
uuid = "b4f34e82-e78d-54a5-968a-f98e89d6e8f7"
version = "0.10.12"
weakdeps = ["ChainRulesCore", "SparseArrays"]

    [deps.Distances.extensions]
    DistancesChainRulesCoreExt = "ChainRulesCore"
    DistancesSparseArraysExt = "SparseArrays"

[[deps.Distributed]]
deps = ["Random", "Serialization", "Sockets"]
uuid = "8ba89e20-285c-5b6f-9357-94700520ee1b"
version = "1.11.0"

[[deps.Distributions]]
deps = ["AliasTables", "FillArrays", "LinearAlgebra", "PDMats", "Printf", "QuadGK", "Random", "SpecialFunctions", "Statistics", "StatsAPI", "StatsBase", "StatsFuns"]
git-tree-sha1 = "3e6d038b77f22791b8e3472b7c633acea1ecac06"
uuid = "31c24e10-a181-5473-b8eb-7969acd0382f"
version = "0.25.120"

    [deps.Distributions.extensions]
    DistributionsChainRulesCoreExt = "ChainRulesCore"
    DistributionsDensityInterfaceExt = "DensityInterface"
    DistributionsTestExt = "Test"

    [deps.Distributions.weakdeps]
    ChainRulesCore = "d360d2e6-b24c-11e9-a2a3-2a2ae2dbcce4"
    DensityInterface = "b429d917-457f-4dbc-8f4c-0cc954292b1d"
    Test = "8dfed614-e22c-5e08-85e1-65c5234f0b40"

[[deps.DocStringExtensions]]
git-tree-sha1 = "7442a5dfe1ebb773c29cc2962a8980f47221d76c"
uuid = "ffbed154-4ef7-542d-bbb7-c09d3a79fcae"
version = "0.9.5"

[[deps.Downloads]]
deps = ["ArgTools", "FileWatching", "LibCURL", "NetworkOptions"]
uuid = "f43a241f-c20a-4ad4-852c-f6b1247861c6"
version = "1.6.0"

[[deps.Enzyme]]
deps = ["CEnum", "EnzymeCore", "Enzyme_jll", "GPUCompiler", "InteractiveUtils", "LLVM", "Libdl", "LinearAlgebra", "ObjectFile", "PrecompileTools", "Preferences", "Printf", "Random", "SparseArrays"]
git-tree-sha1 = "459de98eedc27ea3b19bd1924c11881569cfb834"
uuid = "7da242da-08ed-463a-9acd-ee780be4f1d9"
version = "0.13.55"
weakdeps = ["BFloat16s", "ChainRulesCore", "GPUArraysCore", "LogExpFunctions", "SpecialFunctions", "StaticArrays"]

    [deps.Enzyme.extensions]
    EnzymeBFloat16sExt = "BFloat16s"
    EnzymeChainRulesCoreExt = "ChainRulesCore"
    EnzymeGPUArraysCoreExt = "GPUArraysCore"
    EnzymeLogExpFunctionsExt = "LogExpFunctions"
    EnzymeSpecialFunctionsExt = "SpecialFunctions"
    EnzymeStaticArraysExt = "StaticArrays"

[[deps.EnzymeCore]]
git-tree-sha1 = "8272a687bca7b5c601c0c24fc0c71bff10aafdfd"
uuid = "f151be2c-9106-41f4-ab19-57ee4f262869"
version = "0.8.12"
weakdeps = ["Adapt"]

    [deps.EnzymeCore.extensions]
    AdaptExt = "Adapt"

[[deps.Enzyme_jll]]
deps = ["Artifacts", "JLLWrappers", "LazyArtifacts", "Libdl", "TOML"]
git-tree-sha1 = "49dfd66929c794a6ec806bcb48d4d5d4b1280d11"
uuid = "7cc45869-7501-5eee-bdea-0790c847d4ef"
version = "0.0.184+0"

[[deps.ExprTools]]
git-tree-sha1 = "27415f162e6028e81c72b82ef756bf321213b6ec"
uuid = "e2ba6199-217a-4e67-a87a-7c52f15ade04"
version = "0.1.10"

[[deps.FFTW]]
deps = ["AbstractFFTs", "FFTW_jll", "LinearAlgebra", "MKL_jll", "Preferences", "Reexport"]
git-tree-sha1 = "797762812ed063b9b94f6cc7742bc8883bb5e69e"
uuid = "7a1cc6ca-52ef-59f5-83cd-3a7055c09341"
version = "1.9.0"

[[deps.FFTW_jll]]
deps = ["Artifacts", "JLLWrappers", "Libdl"]
git-tree-sha1 = "6d6219a004b8cf1e0b4dbe27a2860b8e04eba0be"
uuid = "f5851436-0d7a-5f13-b9de-f02708fd171a"
version = "3.3.11+0"

[[deps.FLoops]]
deps = ["BangBang", "Compat", "FLoopsBase", "InitialValues", "JuliaVariables", "MLStyle", "Serialization", "Setfield", "Transducers"]
git-tree-sha1 = "0a2e5873e9a5f54abb06418d57a8df689336a660"
uuid = "cc61a311-1640-44b5-9fba-1b764f453329"
version = "0.2.2"

[[deps.FLoopsBase]]
deps = ["ContextVariablesX"]
git-tree-sha1 = "656f7a6859be8673bf1f35da5670246b923964f7"
uuid = "b9860ae5-e623-471e-878b-f6a53c775ea6"
version = "0.1.1"

[[deps.FileIO]]
deps = ["Pkg", "Requires", "UUIDs"]
git-tree-sha1 = "b66970a70db13f45b7e57fbda1736e1cf72174ea"
uuid = "5789e2e9-d7fb-5bc7-8068-2c6fae9b9549"
version = "1.17.0"

    [deps.FileIO.extensions]
    HTTPExt = "HTTP"

    [deps.FileIO.weakdeps]
    HTTP = "cd3eb016-35fb-5094-929b-558a96fad6f3"

[[deps.FileWatching]]
uuid = "7b1f6079-737a-58dc-b8bc-7a2ca5c1b5ee"
version = "1.11.0"

[[deps.FillArrays]]
deps = ["LinearAlgebra"]
git-tree-sha1 = "6a70198746448456524cb442b8af316927ff3e1a"
uuid = "1a297f60-69ca-5386-bcde-b61e274b549b"
version = "1.13.0"
weakdeps = ["PDMats", "SparseArrays", "Statistics"]

    [deps.FillArrays.extensions]
    FillArraysPDMatsExt = "PDMats"
    FillArraysSparseArraysExt = "SparseArrays"
    FillArraysStatisticsExt = "Statistics"

[[deps.FixedPointNumbers]]
deps = ["Statistics"]
git-tree-sha1 = "05882d6995ae5c12bb5f36dd2ed3f61c98cbb172"
uuid = "53c48c17-4a7d-5ca2-90c5-79b7896eea93"
version = "0.8.5"

[[deps.Flux]]
deps = ["Adapt", "ChainRulesCore", "Compat", "EnzymeCore", "Functors", "LinearAlgebra", "MLCore", "MLDataDevices", "MLUtils", "MacroTools", "NNlib", "OneHotArrays", "Optimisers", "Preferences", "ProgressLogging", "Random", "Reexport", "Setfield", "SparseArrays", "SpecialFunctions", "Statistics", "Zygote"]
git-tree-sha1 = "2c35003ec8dafabdc48549102208b1b15552cb33"
uuid = "587475ba-b771-5e3f-ad9e-33799f191a9c"
version = "0.16.4"

    [deps.Flux.extensions]
    FluxAMDGPUExt = "AMDGPU"
    FluxCUDAExt = "CUDA"
    FluxCUDAcuDNNExt = ["CUDA", "cuDNN"]
    FluxEnzymeExt = "Enzyme"
    FluxMPIExt = "MPI"
    FluxMPINCCLExt = ["CUDA", "MPI", "NCCL"]

    [deps.Flux.weakdeps]
    AMDGPU = "21141c5a-9bdb-4563-92ae-f87d6854732e"
    CUDA = "052768ef-5323-5732-b1bb-66c8b64840ba"
    Enzyme = "7da242da-08ed-463a-9acd-ee780be4f1d9"
    MPI = "da04e1cc-30fd-572f-bb4f-1f8673147195"
    NCCL = "3fe64909-d7a1-4096-9b7d-7a0f12cf0f6b"
    cuDNN = "02a925ec-e4fe-4b08-9a7e-0d78e3d38ccd"

[[deps.ForwardDiff]]
deps = ["CommonSubexpressions", "DiffResults", "DiffRules", "LinearAlgebra", "LogExpFunctions", "NaNMath", "Preferences", "Printf", "Random", "SpecialFunctions"]
git-tree-sha1 = "910febccb28d493032495b7009dce7d7f7aee554"
uuid = "f6369f11-7733-5829-9624-2563aa707210"
version = "1.0.1"
weakdeps = ["StaticArrays"]

    [deps.ForwardDiff.extensions]
    ForwardDiffStaticArraysExt = "StaticArrays"

[[deps.Functors]]
deps = ["Compat", "ConstructionBase", "LinearAlgebra", "Random"]
git-tree-sha1 = "60a0339f28a233601cb74468032b5c302d5067de"
uuid = "d9f16b24-f501-4c13-a1f2-28368ffc5196"
version = "0.5.2"

[[deps.Future]]
deps = ["Random"]
uuid = "9fa8497b-333b-5362-9e8d-4d0656e87820"
version = "1.11.0"

[[deps.GPUArrays]]
deps = ["Adapt", "GPUArraysCore", "KernelAbstractions", "LLVM", "LinearAlgebra", "Printf", "Random", "Reexport", "ScopedValues", "Serialization", "Statistics"]
git-tree-sha1 = "be941842a40b6daac98496994ea69054ba4c5144"
uuid = "0c68f7d7-f131-5f86-a1c3-88cf8149b2d7"
version = "11.2.3"

[[deps.GPUArraysCore]]
deps = ["Adapt"]
git-tree-sha1 = "83cf05ab16a73219e5f6bd1bdfa9848fa24ac627"
uuid = "46192b85-c4d5-4398-a991-12ede77f4527"
version = "0.2.0"

[[deps.GPUCompiler]]
deps = ["ExprTools", "InteractiveUtils", "LLVM", "Libdl", "Logging", "PrecompileTools", "Preferences", "Scratch", "Serialization", "TOML", "Tracy", "UUIDs"]
git-tree-sha1 = "eb1e212e12cc058fa16712082d44be499d23638c"
uuid = "61eb1bfa-7361-4325-ad38-22787b887f55"
version = "1.6.1"

[[deps.GPUToolbox]]
git-tree-sha1 = "15d8b0f5a6dca9bf8c02eeaf6687660dafa638d0"
uuid = "096a3bc2-3ced-46d0-87f4-dd12716f4bfc"
version = "0.2.0"

[[deps.HashArrayMappedTries]]
git-tree-sha1 = "2eaa69a7cab70a52b9687c8bf950a5a93ec895ae"
uuid = "076d061b-32b6-4027-95e0-9a2c6f6d7e74"
version = "0.2.0"

[[deps.HypergeometricFunctions]]
deps = ["LinearAlgebra", "OpenLibm_jll", "SpecialFunctions"]
git-tree-sha1 = "68c173f4f449de5b438ee67ed0c9c748dc31a2ec"
uuid = "34004b35-14d8-5ef3-9330-4cdb6864b03a"
version = "0.3.28"

[[deps.Hyperscript]]
deps = ["Test"]
git-tree-sha1 = "179267cfa5e712760cd43dcae385d7ea90cc25a4"
uuid = "47d2ed2b-36de-50cf-bf87-49c2cf4b8b91"
version = "0.0.5"

[[deps.HypertextLiteral]]
deps = ["Tricks"]
git-tree-sha1 = "7134810b1afce04bbc1045ca1985fbe81ce17653"
uuid = "ac1192a8-f4b3-4bfe-ba22-af5b92cd3ab2"
version = "0.9.5"

[[deps.IOCapture]]
deps = ["Logging", "Random"]
git-tree-sha1 = "b6d6bfdd7ce25b0f9b2f6b3dd56b2673a66c8770"
uuid = "b5f81e59-6552-4d32-b1f0-c071b021bf89"
version = "0.2.5"

[[deps.IRTools]]
deps = ["InteractiveUtils", "MacroTools"]
git-tree-sha1 = "57e9ce6cf68d0abf5cb6b3b4abf9bedf05c939c0"
uuid = "7869d1d1-7146-5819-86e3-90919afe41df"
version = "0.4.15"

[[deps.InfiniteArrays]]
deps = ["ArrayLayouts", "FillArrays", "Infinities", "LazyArrays", "LinearAlgebra"]
git-tree-sha1 = "e61675cbcf3ce57ea3566b0abcfe46e4a521bf6f"
uuid = "4858937d-0d70-526a-a4dd-2d5cb5dd786c"
version = "0.12.15"
weakdeps = ["Statistics"]

    [deps.InfiniteArrays.extensions]
    InfiniteArraysStatisticsExt = "Statistics"

[[deps.Infinities]]
git-tree-sha1 = "437cd9b81b649574582507d8b9ca3ffc981f2fc2"
uuid = "e1ba4f0e-776d-440f-acd9-e1d2e9742647"
version = "0.1.11"

[[deps.InitialValues]]
git-tree-sha1 = "4da0f88e9a39111c2fa3add390ab15f3a44f3ca3"
uuid = "22cec73e-a1b8-11e9-2c92-598750a2cf9c"
version = "0.3.1"

[[deps.InlineStrings]]
git-tree-sha1 = "8594fac023c5ce1ef78260f24d1ad18b4327b420"
uuid = "842dd82b-1e85-43dc-bf29-5d0ee9dffc48"
version = "1.4.4"

    [deps.InlineStrings.extensions]
    ArrowTypesExt = "ArrowTypes"
    ParsersExt = "Parsers"

    [deps.InlineStrings.weakdeps]
    ArrowTypes = "31f734f8-188a-4ce0-8406-c8a06bd891cd"
    Parsers = "69de0a69-1ddd-5017-9359-2bf0b02dc9f0"

[[deps.IntelOpenMP_jll]]
deps = ["Artifacts", "JLLWrappers", "LazyArtifacts", "Libdl"]
git-tree-sha1 = "0f14a5456bdc6b9731a5682f439a672750a09e48"
uuid = "1d5cc7b8-4909-519e-a0f8-d0f5ad9712d0"
version = "2025.0.4+0"

[[deps.InteractiveUtils]]
deps = ["Markdown"]
uuid = "b77e0a4c-d291-57a0-90e8-8db25a27a240"
version = "1.11.0"

[[deps.InverseFunctions]]
git-tree-sha1 = "a779299d77cd080bf77b97535acecd73e1c5e5cb"
uuid = "3587e190-3f89-42d0-90ee-14403ec27112"
version = "0.1.17"
weakdeps = ["Dates", "Test"]

    [deps.InverseFunctions.extensions]
    InverseFunctionsDatesExt = "Dates"
    InverseFunctionsTestExt = "Test"

[[deps.InvertedIndices]]
git-tree-sha1 = "6da3c4316095de0f5ee2ebd875df8721e7e0bdbe"
uuid = "41ab1584-1d38-5bbf-9106-f11c6c58b48f"
version = "1.3.1"

[[deps.IrrationalConstants]]
git-tree-sha1 = "e2222959fbc6c19554dc15174c81bf7bf3aa691c"
uuid = "92d709cd-6900-40b7-9082-c6be49f344b6"
version = "0.2.4"

[[deps.IterTools]]
git-tree-sha1 = "42d5f897009e7ff2cf88db414a389e5ed1bdd023"
uuid = "c8e1da08-722c-5040-9ed9-7db0dc04731e"
version = "1.10.0"

[[deps.IteratorInterfaceExtensions]]
git-tree-sha1 = "a3f24677c21f5bbe9d2a714f95dcd58337fb2856"
uuid = "82899510-4779-5014-852e-03e436cf321d"
version = "1.0.0"

[[deps.JLD2]]
deps = ["FileIO", "MacroTools", "Mmap", "OrderedCollections", "PrecompileTools", "ScopedValues", "TranscodingStreams"]
git-tree-sha1 = "d97791feefda45729613fafeccc4fbef3f539151"
uuid = "033835bb-8acc-5ee8-8aae-3f567f8a3819"
version = "0.5.15"
weakdeps = ["UnPack"]

    [deps.JLD2.extensions]
    UnPackExt = "UnPack"

[[deps.JLLWrappers]]
deps = ["Artifacts", "Preferences"]
git-tree-sha1 = "a007feb38b422fbdab534406aeca1b86823cb4d6"
uuid = "692b3bcd-3c85-4b1f-b108-f13ce0eb3210"
version = "1.7.0"

[[deps.JMcDM]]
deps = ["Requires"]
git-tree-sha1 = "e26d5db41aa1b96d4ed23b46eeeca34116214661"
uuid = "358108f5-d052-4d0a-8344-d5384e00c0e5"
version = "0.7.24"

[[deps.JSON]]
deps = ["Dates", "Mmap", "Parsers", "Unicode"]
git-tree-sha1 = "31e996f0a15c7b280ba9f76636b3ff9e2ae58c9a"
uuid = "682c06a0-de6a-54ab-a142-c8b1cf79cde6"
version = "0.21.4"

[[deps.JuliaNVTXCallbacks_jll]]
deps = ["Artifacts", "JLLWrappers", "Libdl", "Pkg"]
git-tree-sha1 = "af433a10f3942e882d3c671aacb203e006a5808f"
uuid = "9c1d0b0a-7046-5b2e-a33f-ea22f176ac7e"
version = "0.2.1+0"

[[deps.JuliaVariables]]
deps = ["MLStyle", "NameResolution"]
git-tree-sha1 = "49fb3cb53362ddadb4415e9b73926d6b40709e70"
uuid = "b14d175d-62b4-44ba-8fb7-3064adc8c3ec"
version = "0.2.4"

[[deps.KernelAbstractions]]
deps = ["Adapt", "Atomix", "InteractiveUtils", "MacroTools", "PrecompileTools", "Requires", "StaticArrays", "UUIDs"]
git-tree-sha1 = "4efa9cec6f308e0f492ea635421638bff81cf6f8"
uuid = "63c18a36-062a-441e-b654-da1e3ab1ce7c"
version = "0.9.36"
weakdeps = ["EnzymeCore", "LinearAlgebra", "SparseArrays"]

    [deps.KernelAbstractions.extensions]
    EnzymeExt = "EnzymeCore"
    LinearAlgebraExt = "LinearAlgebra"
    SparseArraysExt = "SparseArrays"

[[deps.LLVM]]
deps = ["CEnum", "LLVMExtra_jll", "Libdl", "Preferences", "Printf", "Unicode"]
git-tree-sha1 = "9c7c721cfd800d87d48c745d8bfb65144f0a91df"
uuid = "929cbde3-209d-540e-8aea-75f648917ca0"
version = "9.4.2"
weakdeps = ["BFloat16s"]

    [deps.LLVM.extensions]
    BFloat16sExt = "BFloat16s"

[[deps.LLVMExtra_jll]]
deps = ["Artifacts", "JLLWrappers", "LazyArtifacts", "Libdl", "TOML"]
git-tree-sha1 = "2ea068aac1e7f0337d381b0eae3110581e3f3216"
uuid = "dad2f222-ce93-54a1-a47d-0025e8a3acab"
version = "0.0.37+2"

[[deps.LLVMLoopInfo]]
git-tree-sha1 = "2e5c102cfc41f48ae4740c7eca7743cc7e7b75ea"
uuid = "8b046642-f1f6-4319-8d3c-209ddc03c586"
version = "1.0.0"

[[deps.LaTeXStrings]]
git-tree-sha1 = "dda21b8cbd6a6c40d9d02a73230f9d70fed6918c"
uuid = "b964fa9f-0449-5b57-a5c2-d3ea65f4040f"
version = "1.4.0"

[[deps.LazyArrays]]
deps = ["ArrayLayouts", "FillArrays", "LinearAlgebra", "MacroTools", "MatrixFactorizations", "SparseArrays"]
git-tree-sha1 = "35079a6a869eecace778bcda8641f9a54ca3a828"
uuid = "5078a376-72f3-5289-bfd5-ec5146d43c02"
version = "1.10.0"
weakdeps = ["StaticArrays"]

    [deps.LazyArrays.extensions]
    LazyArraysStaticArraysExt = "StaticArrays"

[[deps.LazyArtifacts]]
deps = ["Artifacts", "Pkg"]
uuid = "4af54fe1-eca0-43a8-85a7-787d91b784e3"
version = "1.11.0"

[[deps.LibCURL]]
deps = ["LibCURL_jll", "MozillaCACerts_jll"]
uuid = "b27032c2-a3e7-50c8-80cd-2d36dbcbfd21"
version = "0.6.4"

[[deps.LibCURL_jll]]
deps = ["Artifacts", "LibSSH2_jll", "Libdl", "MbedTLS_jll", "Zlib_jll", "nghttp2_jll"]
uuid = "deac9b47-8bc7-5906-a0fe-35ac56dc84c0"
version = "8.6.0+0"

[[deps.LibGit2]]
deps = ["Base64", "LibGit2_jll", "NetworkOptions", "Printf", "SHA"]
uuid = "76f85450-5226-5b5a-8eaa-529ad045b433"
version = "1.11.0"

[[deps.LibGit2_jll]]
deps = ["Artifacts", "LibSSH2_jll", "Libdl", "MbedTLS_jll"]
uuid = "e37daf67-58a4-590a-8e99-b0245dd2ffc5"
version = "1.7.2+0"

[[deps.LibSSH2_jll]]
deps = ["Artifacts", "Libdl", "MbedTLS_jll"]
uuid = "29816b5a-b9ab-546f-933c-edad1886dfa8"
version = "1.11.0+1"

[[deps.LibTracyClient_jll]]
deps = ["Artifacts", "JLLWrappers", "Libdl"]
git-tree-sha1 = "d2bc4e1034b2d43076b50f0e34ea094c2cb0a717"
uuid = "ad6e5548-8b26-5c9f-8ef3-ef0ad883f3a5"
version = "0.9.1+6"

[[deps.Libdl]]
uuid = "8f399da3-3557-5675-b5ff-fb832c97cbdb"
version = "1.11.0"

[[deps.LinearAlgebra]]
deps = ["Libdl", "OpenBLAS_jll", "libblastrampoline_jll"]
uuid = "37e2e46d-f89d-539d-b4ee-838fcccc9c8e"
version = "1.11.0"

[[deps.LogExpFunctions]]
deps = ["DocStringExtensions", "IrrationalConstants", "LinearAlgebra"]
git-tree-sha1 = "13ca9e2586b89836fd20cccf56e57e2b9ae7f38f"
uuid = "2ab3a3ac-af41-5b50-aa03-7779005ae688"
version = "0.3.29"

    [deps.LogExpFunctions.extensions]
    LogExpFunctionsChainRulesCoreExt = "ChainRulesCore"
    LogExpFunctionsChangesOfVariablesExt = "ChangesOfVariables"
    LogExpFunctionsInverseFunctionsExt = "InverseFunctions"

    [deps.LogExpFunctions.weakdeps]
    ChainRulesCore = "d360d2e6-b24c-11e9-a2a3-2a2ae2dbcce4"
    ChangesOfVariables = "9e997f8a-9a97-42d5-a9f1-ce6bfc15e2c0"
    InverseFunctions = "3587e190-3f89-42d0-90ee-14403ec27112"

[[deps.Logging]]
uuid = "56ddb016-857b-54e1-b83d-db4d58db5568"
version = "1.11.0"

[[deps.MIMEs]]
git-tree-sha1 = "c64d943587f7187e751162b3b84445bbbd79f691"
uuid = "6c6e2e6c-3030-632d-7369-2d6c69616d65"
version = "1.1.0"

[[deps.MKL_jll]]
deps = ["Artifacts", "IntelOpenMP_jll", "JLLWrappers", "LazyArtifacts", "Libdl", "oneTBB_jll"]
git-tree-sha1 = "5de60bc6cb3899cd318d80d627560fae2e2d99ae"
uuid = "856f044c-d86e-5d09-b602-aeab76dc8ba7"
version = "2025.0.1+1"

[[deps.MLCore]]
deps = ["DataAPI", "SimpleTraits", "Tables"]
git-tree-sha1 = "73907695f35bc7ffd9f11f6c4f2ee8c1302084be"
uuid = "c2834f40-e789-41da-a90e-33b280584a8c"
version = "1.0.0"

[[deps.MLDataDevices]]
deps = ["Adapt", "Compat", "Functors", "Preferences", "Random"]
git-tree-sha1 = "1b351cccb58e366504a5135d10e019234a27d792"
uuid = "7e8f7934-dd98-4c1a-8fe8-92b47a384d40"
version = "1.10.1"

    [deps.MLDataDevices.extensions]
    MLDataDevicesAMDGPUExt = "AMDGPU"
    MLDataDevicesCUDAExt = "CUDA"
    MLDataDevicesChainRulesCoreExt = "ChainRulesCore"
    MLDataDevicesChainRulesExt = "ChainRules"
    MLDataDevicesComponentArraysExt = "ComponentArrays"
    MLDataDevicesFillArraysExt = "FillArrays"
    MLDataDevicesGPUArraysExt = "GPUArrays"
    MLDataDevicesMLUtilsExt = "MLUtils"
    MLDataDevicesMetalExt = ["GPUArrays", "Metal"]
    MLDataDevicesOneHotArraysExt = "OneHotArrays"
    MLDataDevicesReactantExt = "Reactant"
    MLDataDevicesRecursiveArrayToolsExt = "RecursiveArrayTools"
    MLDataDevicesReverseDiffExt = "ReverseDiff"
    MLDataDevicesSparseArraysExt = "SparseArrays"
    MLDataDevicesTrackerExt = "Tracker"
    MLDataDevicesZygoteExt = "Zygote"
    MLDataDevicescuDNNExt = ["CUDA", "cuDNN"]
    MLDataDevicesoneAPIExt = ["GPUArrays", "oneAPI"]

    [deps.MLDataDevices.weakdeps]
    AMDGPU = "21141c5a-9bdb-4563-92ae-f87d6854732e"
    CUDA = "052768ef-5323-5732-b1bb-66c8b64840ba"
    ChainRules = "082447d4-558c-5d27-93f4-14fc19e9eca2"
    ChainRulesCore = "d360d2e6-b24c-11e9-a2a3-2a2ae2dbcce4"
    ComponentArrays = "b0b7db55-cfe3-40fc-9ded-d10e2dbeff66"
    FillArrays = "1a297f60-69ca-5386-bcde-b61e274b549b"
    GPUArrays = "0c68f7d7-f131-5f86-a1c3-88cf8149b2d7"
    MLUtils = "f1d291b0-491e-4a28-83b9-f70985020b54"
    Metal = "dde4c033-4e86-420c-a63e-0dd931031962"
    OneHotArrays = "0b1bfda6-eb8a-41d2-88d8-f5af5cad476f"
    Reactant = "3c362404-f566-11ee-1572-e11a4b42c853"
    RecursiveArrayTools = "731186ca-8d62-57ce-b412-fbd966d074cd"
    ReverseDiff = "37e2e3b7-166d-5795-8a7a-e32c996b4267"
    SparseArrays = "2f01184e-e22b-5df5-ae63-d93ebab69eaf"
    Tracker = "9f7883ad-71c0-57eb-9f7f-b5c9e6d3789c"
    Zygote = "e88e6eb3-aa80-5325-afca-941959d7151f"
    cuDNN = "02a925ec-e4fe-4b08-9a7e-0d78e3d38ccd"
    oneAPI = "8f75cd03-7ff8-4ecb-9b8f-daf728133b1b"

[[deps.MLStyle]]
git-tree-sha1 = "bc38dff0548128765760c79eb7388a4b37fae2c8"
uuid = "d8e11817-5142-5d16-987a-aa16d5891078"
version = "0.4.17"

[[deps.MLUtils]]
deps = ["ChainRulesCore", "Compat", "DataAPI", "DelimitedFiles", "FLoops", "MLCore", "NNlib", "Random", "ShowCases", "SimpleTraits", "Statistics", "StatsBase", "Tables", "Transducers"]
git-tree-sha1 = "a772d8d1987433538a5c226f79393324b55f7846"
uuid = "f1d291b0-491e-4a28-83b9-f70985020b54"
version = "0.4.8"

[[deps.MacroTools]]
git-tree-sha1 = "1e0228a030642014fe5cfe68c2c0a818f9e3f522"
uuid = "1914dd2f-81c6-5fcd-8719-6d5c9610ff09"
version = "0.5.16"

[[deps.Markdown]]
deps = ["Base64"]
uuid = "d6f4376e-aef5-505a-96c1-9c027394607a"
version = "1.11.0"

[[deps.MatrixFactorizations]]
deps = ["ArrayLayouts", "LinearAlgebra", "Printf", "Random"]
git-tree-sha1 = "6731e0574fa5ee21c02733e397beb133df90de35"
uuid = "a3b82374-2e81-5b9e-98ce-41277c0e4c87"
version = "2.2.0"

[[deps.MbedTLS_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "c8ffd9c3-330d-5841-b78e-0817d7145fa1"
version = "2.28.6+0"

[[deps.Metaheuristics]]
deps = ["Distances", "JMcDM", "LinearAlgebra", "Pkg", "Printf", "Random", "Reexport", "Requires", "SearchSpaces", "SnoopPrecompile", "Statistics"]
git-tree-sha1 = "03d457e957cb8238d787525b8fec04ece4cbac9a"
uuid = "bcdb8e00-2c21-11e9-3065-2b553b22f898"
version = "3.4.0"

[[deps.Metalhead]]
deps = ["Artifacts", "BSON", "ChainRulesCore", "Flux", "Functors", "JLD2", "LazyArtifacts", "MLUtils", "NNlib", "PartialFunctions", "Random", "Statistics"]
git-tree-sha1 = "7d3cdd8acb8ccdf82bb80d07f33f020b0976ddc5"
uuid = "dbeba491-748d-5e0e-a39e-b530a07fa0cc"
version = "0.9.5"
weakdeps = ["CUDA"]

    [deps.Metalhead.extensions]
    MetalheadCUDAExt = "CUDA"

[[deps.MicroCollections]]
deps = ["Accessors", "BangBang", "InitialValues"]
git-tree-sha1 = "44d32db644e84c75dab479f1bc15ee76a1a3618f"
uuid = "128add7d-3638-4c79-886c-908ea0c25c34"
version = "0.2.0"

[[deps.Missings]]
deps = ["DataAPI"]
git-tree-sha1 = "ec4f7fbeab05d7747bdf98eb74d130a2a2ed298d"
uuid = "e1d29d7a-bbdc-5cf2-9ac0-f12de2c33e28"
version = "1.2.0"

[[deps.Mmap]]
uuid = "a63ad114-7e13-5084-954f-fe012c677804"
version = "1.11.0"

[[deps.MozillaCACerts_jll]]
uuid = "14a3606d-f60d-562e-9121-12d972cd8159"
version = "2023.12.12"

[[deps.NNlib]]
deps = ["Adapt", "Atomix", "ChainRulesCore", "GPUArraysCore", "KernelAbstractions", "LinearAlgebra", "Random", "ScopedValues", "Statistics"]
git-tree-sha1 = "4abc63cdd8dd9dd925d8e879cda280bedc8013ca"
uuid = "872c559c-99b0-510c-b3b7-b6c96a88d5cd"
version = "0.9.30"

    [deps.NNlib.extensions]
    NNlibAMDGPUExt = "AMDGPU"
    NNlibCUDACUDNNExt = ["CUDA", "cuDNN"]
    NNlibCUDAExt = "CUDA"
    NNlibEnzymeCoreExt = "EnzymeCore"
    NNlibFFTWExt = "FFTW"
    NNlibForwardDiffExt = "ForwardDiff"
    NNlibSpecialFunctionsExt = "SpecialFunctions"

    [deps.NNlib.weakdeps]
    AMDGPU = "21141c5a-9bdb-4563-92ae-f87d6854732e"
    CUDA = "052768ef-5323-5732-b1bb-66c8b64840ba"
    EnzymeCore = "f151be2c-9106-41f4-ab19-57ee4f262869"
    FFTW = "7a1cc6ca-52ef-59f5-83cd-3a7055c09341"
    ForwardDiff = "f6369f11-7733-5829-9624-2563aa707210"
    SpecialFunctions = "276daf66-3868-5448-9aa4-cd146d93841b"
    cuDNN = "02a925ec-e4fe-4b08-9a7e-0d78e3d38ccd"

[[deps.NVTX]]
deps = ["Colors", "JuliaNVTXCallbacks_jll", "Libdl", "NVTX_jll"]
git-tree-sha1 = "1a24c3430fa2ef3317c4c97fa7e431ef45793bd2"
uuid = "5da4648a-3479-48b8-97b9-01cb529c0a1f"
version = "1.0.0"

[[deps.NVTX_jll]]
deps = ["Artifacts", "JLLWrappers", "Libdl"]
git-tree-sha1 = "cd475b587ff77910789a18e68da789fc446a2a05"
uuid = "e98f9f5b-d649-5603-91fd-7774390e6439"
version = "3.2.1+0"

[[deps.NaNMath]]
deps = ["OpenLibm_jll"]
git-tree-sha1 = "9b8215b1ee9e78a293f99797cd31375471b2bcae"
uuid = "77ba4419-2d1f-58cd-9bb1-8ffee604a2e3"
version = "1.1.3"

[[deps.NameResolution]]
deps = ["PrettyPrint"]
git-tree-sha1 = "1a0fa0e9613f46c9b8c11eee38ebb4f590013c5e"
uuid = "71a1bf82-56d0-4bbc-8a3c-48b961074391"
version = "0.1.5"

[[deps.NetworkOptions]]
uuid = "ca575930-c2e3-43a9-ace4-1e988b2c1908"
version = "1.2.0"

[[deps.ObjectFile]]
deps = ["Reexport", "StructIO"]
git-tree-sha1 = "09b1fe6ff16e6587fa240c165347474322e77cf1"
uuid = "d8793406-e978-5875-9003-1fc021f44a92"
version = "0.4.4"

[[deps.OneHotArrays]]
deps = ["Adapt", "ChainRulesCore", "Compat", "GPUArraysCore", "LinearAlgebra", "NNlib"]
git-tree-sha1 = "bfe8e84c71972f77e775f75e6d8048ad3fdbe8bc"
uuid = "0b1bfda6-eb8a-41d2-88d8-f5af5cad476f"
version = "0.2.10"

[[deps.OpenBLAS_jll]]
deps = ["Artifacts", "CompilerSupportLibraries_jll", "Libdl"]
uuid = "4536629a-c528-5b80-bd46-f80d51c5b363"
version = "0.3.27+1"

[[deps.OpenLibm_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "05823500-19ac-5b8b-9628-191a04bc5112"
version = "0.8.1+2"

[[deps.OpenSpecFun_jll]]
deps = ["Artifacts", "CompilerSupportLibraries_jll", "JLLWrappers", "Libdl"]
git-tree-sha1 = "1346c9208249809840c91b26703912dff463d335"
uuid = "efe28fd5-8261-553b-a9e1-b2916fc3738e"
version = "0.5.6+0"

[[deps.Optimisers]]
deps = ["ChainRulesCore", "ConstructionBase", "Functors", "LinearAlgebra", "Random", "Statistics"]
git-tree-sha1 = "131dc319e7c58317e8c6d5170440f6bdaee0a959"
uuid = "3bd65402-5787-11e9-1adc-39752487f4e2"
version = "0.4.6"

    [deps.Optimisers.extensions]
    OptimisersAdaptExt = ["Adapt"]
    OptimisersEnzymeCoreExt = "EnzymeCore"
    OptimisersReactantExt = "Reactant"

    [deps.Optimisers.weakdeps]
    Adapt = "79e6a3ab-5dfb-504d-930d-738a2a938a0e"
    EnzymeCore = "f151be2c-9106-41f4-ab19-57ee4f262869"
    Reactant = "3c362404-f566-11ee-1572-e11a4b42c853"

[[deps.OrderedCollections]]
git-tree-sha1 = "05868e21324cede2207c6f0f466b4bfef6d5e7ee"
uuid = "bac558e1-5e72-5ebc-8fee-abe8a469f55d"
version = "1.8.1"

[[deps.PDMats]]
deps = ["LinearAlgebra", "SparseArrays", "SuiteSparse"]
git-tree-sha1 = "f07c06228a1c670ae4c87d1276b92c7c597fdda0"
uuid = "90014a1f-27ba-587c-ab20-58faa44d9150"
version = "0.11.35"

[[deps.ParameterSchedulers]]
deps = ["InfiniteArrays", "Optimisers"]
git-tree-sha1 = "c62f0da0663704d0472ae578c9bb802c44e70a4c"
uuid = "d7d3b36b-41b8-4d0d-a2bf-768c6151755e"
version = "0.4.3"

[[deps.Parameters]]
deps = ["OrderedCollections", "UnPack"]
git-tree-sha1 = "34c0e9ad262e5f7fc75b10a9952ca7692cfc5fbe"
uuid = "d96e819e-fc66-5662-9728-84c9c7592b0a"
version = "0.12.3"

[[deps.Parsers]]
deps = ["Dates", "PrecompileTools", "UUIDs"]
git-tree-sha1 = "7d2f8f21da5db6a806faf7b9b292296da42b2810"
uuid = "69de0a69-1ddd-5017-9359-2bf0b02dc9f0"
version = "2.8.3"

[[deps.PartialFunctions]]
deps = ["MacroTools"]
git-tree-sha1 = "ba0ea009d9f1e38162d016ca54627314b6d8aac8"
uuid = "570af359-4316-4cb7-8c74-252c00c2016b"
version = "1.2.1"

[[deps.Pkg]]
deps = ["Artifacts", "Dates", "Downloads", "FileWatching", "LibGit2", "Libdl", "Logging", "Markdown", "Printf", "Random", "SHA", "TOML", "Tar", "UUIDs", "p7zip_jll"]
uuid = "44cfe95a-1eb2-52ea-b672-e2afdf69b78f"
version = "1.11.0"
weakdeps = ["REPL"]

    [deps.Pkg.extensions]
    REPLExt = "REPL"

[[deps.PlotlyBase]]
deps = ["ColorSchemes", "Colors", "Dates", "DelimitedFiles", "DocStringExtensions", "JSON", "LaTeXStrings", "Logging", "Parameters", "Pkg", "REPL", "Requires", "Statistics", "UUIDs"]
git-tree-sha1 = "28278bb0053da0fd73537be94afd1682cc5a0a83"
uuid = "a03496cd-edff-5a9b-9e67-9cda94a718b5"
version = "0.8.21"

    [deps.PlotlyBase.extensions]
    DataFramesExt = "DataFrames"
    DistributionsExt = "Distributions"
    IJuliaExt = "IJulia"
    JSON3Ext = "JSON3"

    [deps.PlotlyBase.weakdeps]
    DataFrames = "a93c6f00-e57d-5684-b7b6-d8193f3e46c0"
    Distributions = "31c24e10-a181-5473-b8eb-7969acd0382f"
    IJulia = "7073ff75-c697-5162-941a-fcdaad2a7d2a"
    JSON3 = "0f8b85d8-7281-11e9-16c2-39a750bddbf1"

[[deps.PlutoPlotly]]
deps = ["AbstractPlutoDingetjes", "Artifacts", "ColorSchemes", "Colors", "Dates", "Downloads", "HypertextLiteral", "InteractiveUtils", "LaTeXStrings", "Markdown", "Pkg", "PlotlyBase", "PrecompileTools", "Reexport", "ScopedValues", "Scratch", "TOML"]
git-tree-sha1 = "4fb7c9595eaad32d817cac8c5fa1f90daa83aa4c"
uuid = "8e989ff0-3d88-8e9f-f020-2b208a939ff0"
version = "0.6.3"

    [deps.PlutoPlotly.extensions]
    PlotlyKaleidoExt = "PlotlyKaleido"
    UnitfulExt = "Unitful"

    [deps.PlutoPlotly.weakdeps]
    PlotlyKaleido = "f2990250-8cf9-495f-b13a-cce12b45703c"
    Unitful = "1986cc42-f94f-5a68-af5c-568840ba703d"

[[deps.PlutoUI]]
deps = ["AbstractPlutoDingetjes", "Base64", "ColorTypes", "Dates", "Downloads", "FixedPointNumbers", "Hyperscript", "HypertextLiteral", "IOCapture", "InteractiveUtils", "JSON", "Logging", "MIMEs", "Markdown", "Random", "Reexport", "URIs", "UUIDs"]
git-tree-sha1 = "2b2127e64c1221b8204afe4eb71662b641f33b82"
uuid = "7f904dfe-b85e-4ff6-b463-dae2292396a8"
version = "0.7.66"

[[deps.Polynomials]]
deps = ["LinearAlgebra", "OrderedCollections", "RecipesBase", "Requires", "Setfield", "SparseArrays"]
git-tree-sha1 = "972089912ba299fba87671b025cd0da74f5f54f7"
uuid = "f27b6e38-b328-58d1-80ce-0feddd5e7a45"
version = "4.1.0"

    [deps.Polynomials.extensions]
    PolynomialsChainRulesCoreExt = "ChainRulesCore"
    PolynomialsFFTWExt = "FFTW"
    PolynomialsMakieExt = "Makie"
    PolynomialsMutableArithmeticsExt = "MutableArithmetics"

    [deps.Polynomials.weakdeps]
    ChainRulesCore = "d360d2e6-b24c-11e9-a2a3-2a2ae2dbcce4"
    FFTW = "7a1cc6ca-52ef-59f5-83cd-3a7055c09341"
    Makie = "ee78f7c6-11fb-53f2-987a-cfe4a2b5a57a"
    MutableArithmetics = "d8a4904e-b15c-11e9-3269-09a3773c0cb0"

[[deps.PooledArrays]]
deps = ["DataAPI", "Future"]
git-tree-sha1 = "36d8b4b899628fb92c2749eb488d884a926614d3"
uuid = "2dfb63ee-cc39-5dd5-95bd-886bf059d720"
version = "1.4.3"

[[deps.PrecompileTools]]
deps = ["Preferences"]
git-tree-sha1 = "5aa36f7049a63a1528fe8f7c3f2113413ffd4e1f"
uuid = "aea7be01-6a6a-4083-8856-8a6e6704d82a"
version = "1.2.1"

[[deps.Preferences]]
deps = ["TOML"]
git-tree-sha1 = "9306f6085165d270f7e3db02af26a400d580f5c6"
uuid = "21216c6a-2e73-6563-6e65-726566657250"
version = "1.4.3"

[[deps.PrettyPrint]]
git-tree-sha1 = "632eb4abab3449ab30c5e1afaa874f0b98b586e4"
uuid = "8162dcfd-2161-5ef2-ae6c-7681170c5f98"
version = "0.2.0"

[[deps.PrettyTables]]
deps = ["Crayons", "LaTeXStrings", "Markdown", "PrecompileTools", "Printf", "Reexport", "StringManipulation", "Tables"]
git-tree-sha1 = "1101cd475833706e4d0e7b122218257178f48f34"
uuid = "08abe8d2-0d0c-5749-adfa-8a2ac140af0d"
version = "2.4.0"

[[deps.Printf]]
deps = ["Unicode"]
uuid = "de0858da-6303-5e67-8744-51eddeeeb8d7"
version = "1.11.0"

[[deps.ProgressLogging]]
deps = ["Logging", "SHA", "UUIDs"]
git-tree-sha1 = "d95ed0324b0799843ac6f7a6a85e65fe4e5173f0"
uuid = "33c8b6b6-d38a-422a-b730-caa89a2f386c"
version = "0.1.5"

[[deps.PtrArrays]]
git-tree-sha1 = "1d36ef11a9aaf1e8b74dacc6a731dd1de8fd493d"
uuid = "43287f4e-b6f4-7ad1-bb20-aadabca52c3d"
version = "1.3.0"

[[deps.QuadGK]]
deps = ["DataStructures", "LinearAlgebra"]
git-tree-sha1 = "9da16da70037ba9d701192e27befedefb91ec284"
uuid = "1fd47b50-473d-5c70-9696-f719f8f3bcdc"
version = "2.11.2"
weakdeps = ["Enzyme"]

    [deps.QuadGK.extensions]
    QuadGKEnzymeExt = "Enzyme"

[[deps.REPL]]
deps = ["InteractiveUtils", "Markdown", "Sockets", "StyledStrings", "Unicode"]
uuid = "3fa0cd96-eef1-5676-8a61-b3b8758bbffb"
version = "1.11.0"

[[deps.Random]]
deps = ["SHA"]
uuid = "9a3f8284-a2c9-5f02-9a11-845980a1fd5c"
version = "1.11.0"

[[deps.Random123]]
deps = ["Random", "RandomNumbers"]
git-tree-sha1 = "dbe5fd0b334694e905cb9fda73cd8554333c46e2"
uuid = "74087812-796a-5b5d-8853-05524746bad3"
version = "1.7.1"

[[deps.RandomNumbers]]
deps = ["Random"]
git-tree-sha1 = "c6ec94d2aaba1ab2ff983052cf6a606ca5985902"
uuid = "e6cf234a-135c-5ec9-84dd-332b85af5143"
version = "1.6.0"

[[deps.RealDot]]
deps = ["LinearAlgebra"]
git-tree-sha1 = "9f0a1b71baaf7650f4fa8a1d168c7fb6ee41f0c9"
uuid = "c1ae055f-0cd5-4b69-90a6-9a35b1a98df9"
version = "0.1.0"

[[deps.RecipesBase]]
deps = ["PrecompileTools"]
git-tree-sha1 = "5c3d09cc4f31f5fc6af001c250bf1278733100ff"
uuid = "3cdcf5f2-1ef4-517c-9805-6587b60abb01"
version = "1.3.4"

[[deps.Reexport]]
git-tree-sha1 = "45e428421666073eab6f2da5c9d310d99bb12f9b"
uuid = "189a3867-3050-52da-a836-e630ba90ab69"
version = "1.2.2"

[[deps.Requires]]
deps = ["UUIDs"]
git-tree-sha1 = "62389eeff14780bfe55195b7204c0d8738436d64"
uuid = "ae029012-a4dd-5104-9daa-d747884805df"
version = "1.3.1"

[[deps.Rmath]]
deps = ["Random", "Rmath_jll"]
git-tree-sha1 = "852bd0f55565a9e973fcfee83a84413270224dc4"
uuid = "79098fc4-a85e-5d69-aa6a-4863f24498fa"
version = "0.8.0"

[[deps.Rmath_jll]]
deps = ["Artifacts", "JLLWrappers", "Libdl"]
git-tree-sha1 = "58cdd8fb2201a6267e1db87ff148dd6c1dbd8ad8"
uuid = "f50d1b31-88e8-58de-be2c-1cc44531875f"
version = "0.5.1+0"

[[deps.SHA]]
uuid = "ea8e919c-243c-51af-8825-aaa63cd721ce"
version = "0.7.0"

[[deps.ScopedValues]]
deps = ["HashArrayMappedTries", "Logging"]
git-tree-sha1 = "1147f140b4c8ddab224c94efa9569fc23d63ab44"
uuid = "7e506255-f358-4e82-b7e4-beb19740aa63"
version = "1.3.0"

[[deps.Scratch]]
deps = ["Dates"]
git-tree-sha1 = "9b81b8393e50b7d4e6d0a9f14e192294d3b7c109"
uuid = "6c6a2e73-6563-6170-7368-637461726353"
version = "1.3.0"

[[deps.SearchSpaces]]
deps = ["Combinatorics", "Random"]
git-tree-sha1 = "2662fd537048fb12ff34fabb5249bf50e06f445b"
uuid = "eb7571c6-2196-4f03-99b8-52a5a35b3163"
version = "0.2.0"

[[deps.SentinelArrays]]
deps = ["Dates", "Random"]
git-tree-sha1 = "712fb0231ee6f9120e005ccd56297abbc053e7e0"
uuid = "91c51154-3ec4-41a3-a24f-3f23e20d615c"
version = "1.4.8"

[[deps.Serialization]]
uuid = "9e88b42a-f829-5b0c-bbe9-9e923198166b"
version = "1.11.0"

[[deps.Setfield]]
deps = ["ConstructionBase", "Future", "MacroTools", "StaticArraysCore"]
git-tree-sha1 = "c5391c6ace3bc430ca630251d02ea9687169ca68"
uuid = "efcf1570-3423-57d1-acb7-fd33fddbac46"
version = "1.1.2"

[[deps.ShowCases]]
git-tree-sha1 = "7f534ad62ab2bd48591bdeac81994ea8c445e4a5"
uuid = "605ecd9f-84a6-4c9e-81e2-4798472b76a3"
version = "0.1.0"

[[deps.SimpleTraits]]
deps = ["InteractiveUtils", "MacroTools"]
git-tree-sha1 = "5d7e3f4e11935503d3ecaf7186eac40602e7d231"
uuid = "699a6c99-e7fa-54fc-8d76-47d257e15c1d"
version = "0.9.4"

[[deps.SnoopPrecompile]]
deps = ["Preferences"]
git-tree-sha1 = "e760a70afdcd461cf01a575947738d359234665c"
uuid = "66db9d55-30c0-4569-8b51-7e840670fc0c"
version = "1.0.3"

[[deps.Sockets]]
uuid = "6462fe0b-24de-5631-8697-dd941f90decc"
version = "1.11.0"

[[deps.SortingAlgorithms]]
deps = ["DataStructures"]
git-tree-sha1 = "66e0a8e672a0bdfca2c3f5937efb8538b9ddc085"
uuid = "a2af1166-a08f-5f64-846c-94a0d3cef48c"
version = "1.2.1"

[[deps.SparseArrays]]
deps = ["Libdl", "LinearAlgebra", "Random", "Serialization", "SuiteSparse_jll"]
uuid = "2f01184e-e22b-5df5-ae63-d93ebab69eaf"
version = "1.11.0"

[[deps.SparseInverseSubset]]
deps = ["LinearAlgebra", "SparseArrays", "SuiteSparse"]
git-tree-sha1 = "52962839426b75b3021296f7df242e40ecfc0852"
uuid = "dc90abb0-5640-4711-901d-7e5b23a2fada"
version = "0.1.2"

[[deps.SpatialIndexing]]
git-tree-sha1 = "84efe17c77e1f2156a7a0d8a7c163c1e1c7bdaed"
uuid = "d4ead438-fe20-5cc5-a293-4fd39a41b74c"
version = "0.1.6"

[[deps.SpecialFunctions]]
deps = ["IrrationalConstants", "LogExpFunctions", "OpenLibm_jll", "OpenSpecFun_jll"]
git-tree-sha1 = "41852b8679f78c8d8961eeadc8f62cef861a52e3"
uuid = "276daf66-3868-5448-9aa4-cd146d93841b"
version = "2.5.1"
weakdeps = ["ChainRulesCore"]

    [deps.SpecialFunctions.extensions]
    SpecialFunctionsChainRulesCoreExt = "ChainRulesCore"

[[deps.SplittablesBase]]
deps = ["Setfield", "Test"]
git-tree-sha1 = "e08a62abc517eb79667d0a29dc08a3b589516bb5"
uuid = "171d559e-b47b-412a-8079-5efa626c420e"
version = "0.1.15"

[[deps.StaticArrays]]
deps = ["LinearAlgebra", "PrecompileTools", "Random", "StaticArraysCore"]
git-tree-sha1 = "0feb6b9031bd5c51f9072393eb5ab3efd31bf9e4"
uuid = "90137ffa-7385-5640-81b9-e52037218182"
version = "1.9.13"
weakdeps = ["ChainRulesCore", "Statistics"]

    [deps.StaticArrays.extensions]
    StaticArraysChainRulesCoreExt = "ChainRulesCore"
    StaticArraysStatisticsExt = "Statistics"

[[deps.StaticArraysCore]]
git-tree-sha1 = "192954ef1208c7019899fbf8049e717f92959682"
uuid = "1e83bf80-4336-4d27-bf5d-d5a4f845583c"
version = "1.4.3"

[[deps.Statistics]]
deps = ["LinearAlgebra"]
git-tree-sha1 = "ae3bb1eb3bba077cd276bc5cfc337cc65c3075c0"
uuid = "10745b16-79ce-11e8-11f9-7d13ad32a3b2"
version = "1.11.1"
weakdeps = ["SparseArrays"]

    [deps.Statistics.extensions]
    SparseArraysExt = ["SparseArrays"]

[[deps.StatsAPI]]
deps = ["LinearAlgebra"]
git-tree-sha1 = "9d72a13a3f4dd3795a195ac5a44d7d6ff5f552ff"
uuid = "82ae8749-77ed-4fe6-ae5f-f523153014b0"
version = "1.7.1"

[[deps.StatsBase]]
deps = ["AliasTables", "DataAPI", "DataStructures", "LinearAlgebra", "LogExpFunctions", "Missings", "Printf", "Random", "SortingAlgorithms", "SparseArrays", "Statistics", "StatsAPI"]
git-tree-sha1 = "b81c5035922cc89c2d9523afc6c54be512411466"
uuid = "2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91"
version = "0.34.5"

[[deps.StatsFuns]]
deps = ["HypergeometricFunctions", "IrrationalConstants", "LogExpFunctions", "Reexport", "Rmath", "SpecialFunctions"]
git-tree-sha1 = "8e45cecc66f3b42633b8ce14d431e8e57a3e242e"
uuid = "4c63d2b9-4356-54db-8cca-17b64c39e42c"
version = "1.5.0"
weakdeps = ["ChainRulesCore", "InverseFunctions"]

    [deps.StatsFuns.extensions]
    StatsFunsChainRulesCoreExt = "ChainRulesCore"
    StatsFunsInverseFunctionsExt = "InverseFunctions"

[[deps.StringManipulation]]
deps = ["PrecompileTools"]
git-tree-sha1 = "725421ae8e530ec29bcbdddbe91ff8053421d023"
uuid = "892a3eda-7b42-436c-8928-eab12a02cf0e"
version = "0.4.1"

[[deps.StructArrays]]
deps = ["ConstructionBase", "DataAPI", "Tables"]
git-tree-sha1 = "8ad2e38cbb812e29348719cc63580ec1dfeb9de4"
uuid = "09ab397b-f2b6-538f-b94a-2f83cf4a842a"
version = "0.7.1"
weakdeps = ["Adapt", "GPUArraysCore", "KernelAbstractions", "LinearAlgebra", "SparseArrays", "StaticArrays"]

    [deps.StructArrays.extensions]
    StructArraysAdaptExt = "Adapt"
    StructArraysGPUArraysCoreExt = ["GPUArraysCore", "KernelAbstractions"]
    StructArraysLinearAlgebraExt = "LinearAlgebra"
    StructArraysSparseArraysExt = "SparseArrays"
    StructArraysStaticArraysExt = "StaticArrays"

[[deps.StructIO]]
git-tree-sha1 = "c581be48ae1cbf83e899b14c07a807e1787512cc"
uuid = "53d494c1-5632-5724-8f4c-31dff12d585f"
version = "0.3.1"

[[deps.StyledStrings]]
uuid = "f489334b-da3d-4c2e-b8f0-e476e12c162b"
version = "1.11.0"

[[deps.SuiteSparse]]
deps = ["Libdl", "LinearAlgebra", "Serialization", "SparseArrays"]
uuid = "4607b0f0-06f3-5cda-b6b1-a6196a1729e9"

[[deps.SuiteSparse_jll]]
deps = ["Artifacts", "Libdl", "libblastrampoline_jll"]
uuid = "bea87d4a-7f5b-5778-9afe-8cc45184846c"
version = "7.7.0+0"

[[deps.TOML]]
deps = ["Dates"]
uuid = "fa267f1f-6049-4f14-aa54-33bafae1ed76"
version = "1.0.3"

[[deps.TableTraits]]
deps = ["IteratorInterfaceExtensions"]
git-tree-sha1 = "c06b2f539df1c6efa794486abfb6ed2022561a39"
uuid = "3783bdb8-4a98-5b6b-af9a-565f29a5fe9c"
version = "1.0.1"

[[deps.Tables]]
deps = ["DataAPI", "DataValueInterfaces", "IteratorInterfaceExtensions", "OrderedCollections", "TableTraits"]
git-tree-sha1 = "f2c1efbc8f3a609aadf318094f8fc5204bdaf344"
uuid = "bd369af6-aec1-5ad0-b16a-f7cc5008161c"
version = "1.12.1"

[[deps.Tar]]
deps = ["ArgTools", "SHA"]
uuid = "a4e569a6-e804-4fa4-b0f3-eef7a1d5b13e"
version = "1.10.0"

[[deps.TensorCore]]
deps = ["LinearAlgebra"]
git-tree-sha1 = "1feb45f88d133a655e001435632f019a9a1bcdb6"
uuid = "62fd8b95-f654-4bbd-a8a5-9c27f68ccd50"
version = "0.1.1"

[[deps.Test]]
deps = ["InteractiveUtils", "Logging", "Random", "Serialization"]
uuid = "8dfed614-e22c-5e08-85e1-65c5234f0b40"
version = "1.11.0"

[[deps.Tracy]]
deps = ["ExprTools", "LibTracyClient_jll", "Libdl"]
git-tree-sha1 = "91dbaee0f50faa4357f7e9fc69442c7b6364dfe5"
uuid = "e689c965-62c8-4b79-b2c5-8359227902fd"
version = "0.1.5"

    [deps.Tracy.extensions]
    TracyProfilerExt = "TracyProfiler_jll"

    [deps.Tracy.weakdeps]
    TracyProfiler_jll = "0c351ed6-8a68-550e-8b79-de6f926da83c"

[[deps.TranscodingStreams]]
git-tree-sha1 = "0c45878dcfdcfa8480052b6ab162cdd138781742"
uuid = "3bb67fe8-82b1-5028-8e26-92a6c54297fa"
version = "0.11.3"

[[deps.Transducers]]
deps = ["Accessors", "ArgCheck", "BangBang", "Baselet", "CompositionsBase", "ConstructionBase", "DefineSingletons", "Distributed", "InitialValues", "Logging", "Markdown", "MicroCollections", "Requires", "SplittablesBase", "Tables"]
git-tree-sha1 = "7deeab4ff96b85c5f72c824cae53a1398da3d1cb"
uuid = "28d57a85-8fef-5791-bfe6-a80928e7c999"
version = "0.4.84"

    [deps.Transducers.extensions]
    TransducersAdaptExt = "Adapt"
    TransducersBlockArraysExt = "BlockArrays"
    TransducersDataFramesExt = "DataFrames"
    TransducersLazyArraysExt = "LazyArrays"
    TransducersOnlineStatsBaseExt = "OnlineStatsBase"
    TransducersReferenceablesExt = "Referenceables"

    [deps.Transducers.weakdeps]
    Adapt = "79e6a3ab-5dfb-504d-930d-738a2a938a0e"
    BlockArrays = "8e7c35d0-a365-5155-bbbb-fb81a777f24e"
    DataFrames = "a93c6f00-e57d-5684-b7b6-d8193f3e46c0"
    LazyArrays = "5078a376-72f3-5289-bfd5-ec5146d43c02"
    OnlineStatsBase = "925886fa-5bf2-5e8e-b522-a9147a512338"
    Referenceables = "42d2dcc6-99eb-4e98-b66c-637b7d73030e"

[[deps.Tricks]]
git-tree-sha1 = "6cae795a5a9313bbb4f60683f7263318fc7d1505"
uuid = "410a4b4d-49e4-4fbc-ab6d-cb71b17b3775"
version = "0.1.10"

[[deps.URIs]]
git-tree-sha1 = "bef26fb046d031353ef97a82e3fdb6afe7f21b1a"
uuid = "5c2747f8-b7ea-4ff2-ba2e-563bfd36b1d4"
version = "1.6.1"

[[deps.UUIDs]]
deps = ["Random", "SHA"]
uuid = "cf7118a7-6976-5b1a-9a39-7adc72f591a4"
version = "1.11.0"

[[deps.UnPack]]
git-tree-sha1 = "387c1f73762231e86e0c9c5443ce3b4a0a9a0c2b"
uuid = "3a884ed6-31ef-47d7-9d2a-63182c4928ed"
version = "1.0.2"

[[deps.Unicode]]
uuid = "4ec0a83e-493e-50e2-b9ac-8f72acf5a8f5"
version = "1.11.0"

[[deps.UnsafeAtomics]]
git-tree-sha1 = "b13c4edda90890e5b04ba24e20a310fbe6f249ff"
uuid = "013be700-e6cd-48c3-b4a1-df204f14c38f"
version = "0.3.0"
weakdeps = ["LLVM"]

    [deps.UnsafeAtomics.extensions]
    UnsafeAtomicsLLVM = ["LLVM"]

[[deps.Zlib_jll]]
deps = ["Libdl"]
uuid = "83775a58-1f1d-513f-b197-d71354ab007a"
version = "1.2.13+1"

[[deps.Zygote]]
deps = ["AbstractFFTs", "ChainRules", "ChainRulesCore", "DiffRules", "Distributed", "FillArrays", "ForwardDiff", "GPUArraysCore", "IRTools", "InteractiveUtils", "LinearAlgebra", "LogExpFunctions", "MacroTools", "NaNMath", "PrecompileTools", "Random", "SparseArrays", "SpecialFunctions", "Statistics", "ZygoteRules"]
git-tree-sha1 = "a29cbf3968d36022198bcc6f23fdfd70f7caf737"
uuid = "e88e6eb3-aa80-5325-afca-941959d7151f"
version = "0.7.10"

    [deps.Zygote.extensions]
    ZygoteAtomExt = "Atom"
    ZygoteColorsExt = "Colors"
    ZygoteDistancesExt = "Distances"
    ZygoteTrackerExt = "Tracker"

    [deps.Zygote.weakdeps]
    Atom = "c52e3926-4ff0-5f6e-af25-54175e0327b1"
    Colors = "5ae59095-9a9b-59fe-a467-6f913c188581"
    Distances = "b4f34e82-e78d-54a5-968a-f98e89d6e8f7"
    Tracker = "9f7883ad-71c0-57eb-9f7f-b5c9e6d3789c"

[[deps.ZygoteRules]]
deps = ["ChainRulesCore", "MacroTools"]
git-tree-sha1 = "434b3de333c75fc446aa0d19fc394edafd07ab08"
uuid = "700de1a5-db45-46bc-99cf-38207098b444"
version = "0.2.7"

[[deps.cuDNN]]
deps = ["CEnum", "CUDA", "CUDA_Runtime_Discovery", "CUDNN_jll"]
git-tree-sha1 = "8c20cd99f74552772a26712578db42a8a4200cec"
uuid = "02a925ec-e4fe-4b08-9a7e-0d78e3d38ccd"
version = "1.4.3"

[[deps.demumble_jll]]
deps = ["Artifacts", "JLLWrappers", "Libdl"]
git-tree-sha1 = "6498e3581023f8e530f34760d18f75a69e3a4ea8"
uuid = "1e29f10c-031c-5a83-9565-69cddfc27673"
version = "1.3.0+0"

[[deps.libblastrampoline_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "8e850b90-86db-534c-a0d3-1478176c7d93"
version = "5.11.0+0"

[[deps.nghttp2_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "8e850ede-7688-5339-a07c-302acd2aaf8d"
version = "1.59.0+0"

[[deps.oneTBB_jll]]
deps = ["Artifacts", "JLLWrappers", "Libdl"]
git-tree-sha1 = "d5a767a3bb77135a99e433afe0eb14cd7f6914c3"
uuid = "1317d2d5-d96f-522e-a858-c73665f53c3e"
version = "2022.0.0+0"

[[deps.p7zip_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "3f19e933-33d8-53b3-aaab-bd5110c3b7a0"
version = "17.4.0+2"
"""

# ‚ïî‚ïê‚ï° Cell order:
# ‚ïü‚îÄ461f0505-2230-4b84-b6c6-1a9730808437
# ‚ï†‚ïê97ae4222-5a3e-4cbd-b4d1-aa028d3e4ca8
# ‚ï†‚ïêd73472ff-9e09-45b0-8811-b7dd8d820358
# ‚ï†‚ïê26fb86d5-c844-469a-aef5-ed3c2a9ba949
# ‚ï†‚ïêa91e28fb-e769-418d-953f-0e0bb366d853
# ‚ï†‚ïê6db97fc1-8f11-42df-bffe-f86b8619a399
# ‚ïü‚îÄ29d41554-3a0a-4972-a9e5-54c998429acd
# ‚ï†‚ïêfc228dea-21fc-4fcd-82a9-7ac3bc7ee722
# ‚ï†‚ïê7c39a024-bf46-4024-b0da-a4d6092e864d
# ‚ï†‚ïê139490d1-5931-4a18-9f74-c391064a3383
# ‚ï†‚ïê7c59cbf9-38d5-45fb-bf7d-9af8f241ccf6
# ‚ïü‚îÄce690827-fa3f-48bc-bc09-1df5ee15f683
# ‚ï†‚ïêa5302fa2-4f67-4ed6-96ce-dda78a160ffe
# ‚ï†‚ïê1121e34c-ca35-4f68-8283-eca514928654
# ‚ïü‚îÄae96f920-5828-4c5f-b69f-48d8c4fee378
# ‚ï†‚ïê96aebf7d-2112-4a4d-9993-6f53f40ffca5
# ‚ïü‚îÄea372a8f-212f-425d-947c-b57bba6b5574
# ‚ï†‚ïê32baae21-b5fa-4391-9066-23436a5a2b1d
# ‚ï†‚ïê89599b3f-8c20-46c5-8f5c-ccbb71b26b36
# ‚ï†‚ïê64430447-c267-4eec-8d38-63ccf91d82c4
# ‚ï†‚ïê5847ea08-43ca-4c6d-a694-0017d7396f60
# ‚ï†‚ïê4fb77fae-61bb-4484-b733-82e1d1002371
# ‚ï†‚ïêaeb16356-9cbb-4d07-9623-25df66e94378
# ‚ïü‚îÄ747680b0-3469-426c-8b9e-4ab8ca04a6de
# ‚ï†‚ïêbf31f347-bc9a-4bf8-a086-99dba2f6fea0
# ‚ï†‚ïê190c8221-c5c7-48f9-b016-36c27fd4528c
# ‚ïü‚îÄ62681bba-5486-4957-8433-4258657399b8
# ‚ï†‚ïê0fbf59a9-74bc-479f-879c-3f72f7c76489
# ‚ï†‚ïê0dd8d418-a664-4ecd-ac90-bab97861f9f0
# ‚ïü‚îÄfacd01fe-b288-437f-96dd-a8a4d9afd8fe
# ‚ï†‚ïê06a8d9e2-495c-4a25-8c23-527ba1b8e089
# ‚ï†‚ïê4cc4fea4-2a3b-11ee-1341-d7fa7529b14a
# ‚ï†‚ïêe00065be-8bbc-41b2-b62b-3c8ad56a5bd8
# ‚ïü‚îÄa08bfd70-e464-4c5e-b1a3-860fa8cd438a
# ‚ï†‚ïê99e35014-80dc-49c6-939e-26fa0e2d7c6f
# ‚ïü‚îÄeac9b092-b778-4c32-a0c5-de2eb4aa1b83
# ‚ï†‚ïê81b79f2f-9567-40c3-964e-b5a4ee96a317
# ‚ï†‚ïê06134111-d442-4195-9c6a-43443babed8e
# ‚ïü‚îÄ66bddc43-ca9f-43cd-85a3-d33b11a6c033
# ‚ï†‚ïê8684c192-d1b9-4821-a02e-2c7300af9b3c
# ‚ï†‚ïêe9efedc1-8287-4676-ba64-a4abc77da18d
# ‚ï†‚ïêb65ae9dc-dd50-4007-9894-cadef28e0552
# ‚ïü‚îÄ52dc9696-3e0b-42c7-b6cf-7a07ca3cb4dd
# ‚ï†‚ïêfa646879-158a-4cbb-be0e-d375cf486ba0
# ‚ïü‚îÄeafab001-87a7-423f-917f-1fbd46699186
# ‚ï†‚ïê237ad98e-75db-41fc-b378-b895facdd8d9
# ‚ïü‚îÄ5ed89ee8-325b-4757-b348-e6c1a3d277ad
# ‚ï†‚ïê04f9b328-edc8-4b1e-9a7c-79a215b1cf5f
# ‚ïü‚îÄ371354f6-29e7-4227-b006-f2daacb08ce7
# ‚ï†‚ïê186713a3-c357-427c-9af4-6739de2d33c5
# ‚ïü‚îÄfe87efed-9c40-4869-bdf3-cc60eb5b6436
# ‚ï†‚ïê76c4f167-11b5-48a3-b3b3-4fe8fd9646c1
# ‚ï†‚ïê78e16b27-85c3-4d4a-9238-3ec2a33c9c88
# ‚ïü‚îÄefde2571-4e1d-4626-9081-86d513707f5e
# ‚ï†‚ïêd74b7838-98c4-4356-8a0d-1a2388369788
# ‚ïü‚îÄ95660df0-088b-49f3-b875-fca19a82d024
# ‚ï†‚ïêc49e3d81-27ba-4a4f-870a-ae218a505dd0
# ‚ïü‚îÄ5731aea5-af70-4dc3-a505-2f48fce02e8e
# ‚ï†‚ïê56055fa2-8f96-4b43-b1eb-2cd5a9cbadeb
# ‚ï†‚ïê90e69a62-b340-45d6-944e-cb56f6f46ca6
# ‚ï†‚ïêe80dd767-72ef-410b-b7a2-38e0545a5df3
# ‚ï†‚ïê1f139691-e19f-41e5-8113-3cc00e8fe2b8
# ‚ï†‚ïê825dda0d-6472-405c-b149-5c4d2202963f
# ‚ï†‚ïê8abc3a6d-d2f5-4527-a828-793364706fa5
# ‚ï†‚ïê84d56fa3-50de-48ad-8e07-dfaecc1cfdf3
# ‚ï†‚ïê86a120ae-8865-4e99-a028-f567f3c1bbad
# ‚ïü‚îÄf4238f8e-3596-4c98-a64e-477c3aa2b054
# ‚ï†‚ïêa48d23b6-86d6-4232-a1b9-300e65b264ff
# ‚ï†‚ïê84aa58d3-115b-4d2d-a798-fc936f5bb2ca
# ‚ï†‚ïêa46ce69a-3081-4e86-b9eb-c773c772f459
# ‚ï†‚ïê2b3bf9d1-87cc-4884-b3d7-f1b81f6769dc
# ‚ï†‚ïêafb6c675-0ef8-445c-a204-795e300c8589
# ‚ï†‚ïê88e02d85-85df-4913-be59-1fc836f39114
# ‚ï†‚ïêfafede49-59df-47e0-a870-74b946a36af5
# ‚ï†‚ïêa85b6958-d894-45cc-86c6-933fba757e1c
# ‚ï†‚ïê74c8e79f-b1c8-484b-86bf-65c2a2831b53
# ‚ï†‚ïê073c77d1-7598-45d3-858d-9222f2e4c590
# ‚ï†‚ïêc4de28ea-5af6-4c66-9955-a5d168833036
# ‚ï†‚ïêb2e5505d-819d-4a48-b763-d81b4065b32b
# ‚ï†‚ïêb3428bd8-c1ec-4e48-97b0-3dbde763292b
# ‚ï†‚ïêd62474f6-48fb-49fe-919b-c4373135067c
# ‚ïü‚îÄab3f0de4-3e7e-4d5f-aa1a-25fe24a52b38
# ‚ï†‚ïêf5e6cf15-1072-4037-9a96-91db93e730f0
# ‚ï†‚ïêd966211f-012e-45f2-b9ae-abf599666edf
# ‚ï†‚ïê97b37ee3-e87b-4942-9d9a-22cffc88ab9d
# ‚ï†‚ïê6d34151a-b539-4eda-995a-b7f873719a4c
# ‚ï†‚ïê4ec8578c-a202-4a3d-9425-60bf623a3a02
# ‚ï†‚ïê0db6b854-ef75-46c0-8e19-efd8faa037bb
# ‚ï†‚ïê41b5d143-6a0f-4f4c-8e62-8483d9e0d5f6
# ‚ï†‚ïêe57556e8-b287-4bc5-9ea1-4f68948eccf2
# ‚ï†‚ïê6e7c70c8-cffe-4b30-85b4-5942fbb60da8
# ‚ï†‚ïêe46630eb-5e29-4c5e-b792-0f7ca0af0ff0
# ‚ï†‚ïê361ead1b-3fe3-4ae2-b018-2c6904d0f889
# ‚ï†‚ïê4e527961-5734-4294-9f3c-e2aa8314eef6
# ‚ï†‚ïê234d7462-e4bd-4a7c-9ed4-7160a6a9ffb9
# ‚ï†‚ïê7931ce6a-a062-4c7f-bb04-82b822e04eab
# ‚ï†‚ïêeafe181e-19e9-409e-ad1d-ce859cf0e672
# ‚ï†‚ïê7f8094da-d6a6-4b3d-b16c-cb0d7e928b9d
# ‚ï†‚ïê7e3a8840-ed33-4d7c-a3b0-f6f458e2a72d
# ‚ï†‚ïê0541d3c6-24cf-46b1-95a1-39f3341aec4f
# ‚ï†‚ïê483e596b-afbc-45d5-84d4-847959c5b6ea
# ‚ïü‚îÄ61fbbf84-1b2b-4de9-8763-800f76c851e0
# ‚ï†‚ïê0f0fe0e8-a239-474b-b9af-54507cb968aa
# ‚ï†‚ïê7531c2eb-5505-4ad2-9f79-111bed3bef74
# ‚ïü‚îÄ5d25db74-dcc2-49d6-b62a-39f612089e9f
# ‚ï†‚ïêc9f4b3e6-6691-4e7f-86c7-dcacdde924a5
# ‚ïü‚îÄ0a2fb24a-3c7a-46ed-ad54-d35fb72f8031
# ‚ï†‚ïê1a8619c6-4c19-4f55-a968-d18a4f1016e7
# ‚ïü‚îÄ63f7880d-9353-4857-b751-36b6f5f45d68
# ‚ïü‚îÄ00000000-0000-0000-0000-000000000001
# ‚ïü‚îÄ00000000-0000-0000-0000-000000000002
